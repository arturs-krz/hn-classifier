{
	"_id": "14456562",
	"site": "https://github.com/cybertec-postgresql/pg_squeeze",
	"title": "Pg_squeeze: A PostgreSQL extension for automatic bloat cleanup",
	"author": "andruby",
	"date": "2017-06-13T13:55:01.681Z",
	"tags": {
		"categories": [
			"opensource",
			"postgres",
			"cleanup"
		],
		"languages": [
			"c",
			"plpgsql",
			"makefile"
		]
	},
	"content": "readme pg_squeeze is extension removes unused space a table optionally sorts tuples according particular index ( if cluster [2]command was executed concurrently regular reads / writes). fact try replace pg_repack [1] extension.while providing very similar functionality, pg_squeeze takes differentapproach it 1. implements functionality purely server side. 2. utilizes recent improvements postgresql database server.while 1) makes both configuration use simpler (compared [1] usesboth server client side code), also allows rather smoothimplementation unattended processing using background workers [3]. for 2), important difference (besides use background workers) is we logical decoding [4] instead triggers capture concurrentchanges.installation------------1. set pg_config envoirnment variable point pg_config command your postgresql installation.2. 3. sudo install4. apply following settings postgresql.conf: wal_level = logical max_replication_slots = 1 # ... add 1 the current value. shared_preload_libraries = 'pg_squeeze' # ... add library the existing ones.5. start pg cluster.6. a superuser, run create extension pg_squeeze;note: you remove extension particular database, sure database has \"squeeze worker\" ( \"enable / disable table processing\"section) running. otherwise drop extension command hang until 'scancelled.register table regular processing-------------------------------------, make sure your table has either primary key uniqueconstraint. is necessary process changes transactions might while \"pg_squeeze\" is doing work. make \"pg_squeeze\" extension aware the table, need insert record \"squeeze.tables\" table. once added, statistics the table arechecked periodically. whenever table meets criteria be \"squeezed\", \"task\" is added a queue. tasks are processed sequentially, the order were created. simplest \"registration\" looks insert squeeze.tables (tabschema, tabname, schedule)values ('public', 'foo', '{22:30, 03:00}');additional columns be specified optionally, example:insert squeeze.tables(tabschema, tabname, schedule, free_space_extra, vacuum_max_age,max_retry)values ('public', 'bar', '{22:30, 03:00}', 30, '2 hours', 2);following is complete description table metadata.* \"tabschema\" \"tabname\" are schema table name respectively.* \"schedule\" column tells which times the the table should checked. such check possibly result a processing task.* \"free_space_extra\" is minimum percentage \"extra free space\" needed trigger processing the table. \"extra\" adjective refers the fact free space derived \"fillfactor\" is reason squeeze table. example, \"fillfactor\" is equal 60, at least 40 percent each page should stay free during normal operation. you to ensure 70 percent free space makes pg_squeeze interested the table, set \"free_space_extra\" 30 ( is 70 percent required be free minus 40 percent free due the \"fillfactor\"). default value \"free_space_extra\" is 50.* \"min_size\" is minimum disk space megabytes table must occupy be eligible processing. default value is 8.* \"vacuum_max_age\" is maximum since completion the last vacuum consider free space map (fsm) fresh. once interval has elapsed, portion dead tuples might significant so more effort simply checking fsm needs be spent evaluate potential effect \"pg_squeeze\". default value is 1 hour.* \"max_retry\" is maximum number extra attempts squeeze table the processing the corresponding task failed. typical reason retry processing is table definition got changed while table was being squeezed. the number retries is achieved, processing the table is considered complete. next task is created soon time specified \"task_interval\" column \"squeeze.tables\" table has elapsed. default value \"max_retry\" is 0 (.e. not retry).* \"clustering_index\" is existing index the processed table. once processing is finished, tuples the table be physically sorted the key this index.* \"rel_tablespace\" is existing tablespace table should moved . null means the table should stay where is.* \"ind_tablespaces\" is two-dimensional array which each row specifies tablespace mapping an index. first the second columns represent index name tablespace name respectively. indexes which mapping is specified stay the original tablespace. regarding tablespaces, special case is worth mention: tablespace is specified table not indexes, table gets moved that tablespace the indexes stay the original (i.e. tablespace the table is the default indexes one might expect).* \"skip_analyze\" indicates table processing should be followed analyze command. default value is \"false\", meaning analyze is performed default.caution! \"squeeze.table\" is only table user should modify. you tochange anything else, sure perfectly understand you are doing.enable / disable table processing--------------------------------- enable automated processing, run statement superuser:select squeeze.start_worker(); function starts background worker periodically checks of registered tables are eligible squeeze creates executes tasks them. the worker is already running the current database, functiondoes return pid a worker, that worker exit immediately. the background worker is running, can the following statement stop :select squeeze.stop_worker();caution! the functions mentioned this section are considered userinterface. you to call other , make sure perfectlyunderstand you're doing. there's work do, worker sleeps before checking again. delayis controlled guc parameter \"squeeze.worker_naptime\". 's measured seconds the default value is 1 minute. you the background worker start automatically during startup thewhole postgresql cluster, add entries this postgresql.conf filesqueeze.worker_autostart = 'my_database your_database'squeeze.worker_role = postgresnext you start cluster, worker be launched \"my_database\" one \"your_database\". you this approach, note any worker either reject start will stop without doing work 1. \"pg_squeeze\" extension does exist the database.. 2. squeeze.worker_role parameter specifies role does have superuser privileges.control impact other backends------------------------------------although table being squeezed is available both read writeoperations other transactions of time, exclusive lock is needed finalize processing. pg_squeeze occasionally seems block access tables too much, consider setting \"squeeze.max_xlock_time\" guc parameter. exampleset squeeze.max_xlock_time 100;tells the exclusive lock shouldn't held more 0.1 second (100milliseconds). more is needed the final stage, pg_squeeze releases exclusive lock, processes changes committed other transactions between tries final stage again. error is reported the lockduration is exceeded few more times. that happens, should eitherincrease setting schedule processing the problematic table adifferent daytime, the write activity is lower.monitoring----------\"squeeze.log\" table contains entry per successfully squeezed table.\"squeeze.errors\" table contains errors happened during squeezing. usual problem reported here is someone changed definition (e.g. added removed column) the table whose processing was in progress.unregister table---------------- particular table should longer subject periodical squeeze, simplydelete corresponding row \"squeeze.tables\" table.'s a practice unregister table you're going drop,although background worker does unregister non-existing tablesperiodically.notes concurrency--------------------1. extension does prevent transactions altering table certain stages the processing. a \"disruptive command\" (.e. alter table,vacuum full, cluster truncate) manages commit before squeeze finish, squeeze_table() function aborts all changes done the tableare rolled . the \"max_retry\" column \"squeeze.tables\" table determines many times squeeze worker retry. besides , change schedulemight help to avoid disruptions.2. [1], pg_squeeze changes visibility rows thus allows mvcc-unsafe behavior described the paragraph [5].references----------[1] http://reorg.github.com/pg_repack[2] https://www.postgresql.org/docs/9.6/static/sql-cluster.html[3] https://www.postgresql.org/docs/9.6/static/bgworker.html[4] https://www.postgresql.org/docs/9.6/static/logicaldecoding.html[5] https://www.postgresql.org/docs/9.6/static/mvcc-caveats.html"
}