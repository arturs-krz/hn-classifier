{
	"_id": "14527298",
	"site": "https://github.com/indrajithi/mgc-django",
	"title": " Music Genre Classification App in Django",
	"author": "l1feh4ck",
	"date": "2017-06-13T13:23:08.985Z",
	"tags": {
		"categories": [
			"opensource"
		],
		"languages": [
			"python",
			"html"
		]
	},
	"content": "readme.md music genre classifiertable contentsintroductionrequirementsinstallationmusic genre classifier apparchitectureflow chartprototypefeature extractionprincipal component analysis.dimensionality reductionclassificationk-nearest neighbors (knn)logistic regressionpython package mysvmfeaturesvmaccresultsconclusionlicenseintroductionmusic is categorized subjective categories called genres. the growth the internet multimedia systems applications deal the musical databases gained importance demand music information retrieval (mir) applications increased. musical genres no strict definitions boundaries they arise through complex interaction between public, marketing, historical, cultural factors. is web application classify music to genres.requirementsdjango (1.11)numpy (1.12.1)scikit-learn (0.18.1)scipy (0.19.0)python-speech-features (0.5)pydub (0.18.0)installationgit clone https://github.com/indrajithi/mgc-django.gitpip install -r requirements.txtpython manage.py migratepython manage.py runserverapp run localhost:8000music genre classifier app web application is written python using django framework. uses trained poly kernel svm finding genre. every http request is gone the url dispatcher urls.py will contain view present views.py. can write rules views.py handle each http request that url. have written views http post get requests upload music find genre. need be models (models.py) files we store the database. file is automatically deleted once find genre.python objects be saved to disk using module joblib sklearn.externals: joblib.dump (object, filename). trained classifier is saved to disk loaded joblib.load(filename). since training dataset is small, classifier object does need be compressed. web application uses package mysvm we developed extract features to find genre label.architectureflow chart browser send http request get post our web app. request be loading templates is html file for static file, includes front end javascript files (js), stylesheets (css), true type fonts(ttf) image files. user upload file a http post. front end javascript convert given file blob (binary large objects) files size 1mb before post. a successful post, user send get request finding genre label. have developed python package called mysvm extracting features classifying music. package is added our web app. receiving get request genre label, convert file .wav it is other format. the features are extracted the audio file using mysvm.feature.extract (filename). genre labels be found mysvm.svm.getgenre(filename) function call. multi option is selected the user mysvm.svm.getmultigenre(filename) function is called. will all probabilities a genres the given music belongs . if probability is greater 0.15, will push label the stack maximum size 3. labels are sent json data the response. single genre label is selected label is having highest probability is sent response.prototype need find best classification algorithm can used our web app. matlab is ideal implement machine learning algorithms minimum lines code. before making web app python made prototype matlab.feature extraction chose extract mfcc the audio files the feature. finding mfcc matlab, have used htk mfcc matlab toolkit. output be matrix 13n dimensional vector. where n depends the total duration the audio. 13(100*sec).while feature extraction were getting nan( a number) infinity the output. is usually caused a division zero a very small number closed 0 resulting infinity/nan the output. could a regular result some algorithm implementation error the mfcc toolkit. overcome situation, have set nan infinity entries the feature array 0.principal component analysis.principal component analysis (pca) is statistical procedure uses orthogonal transformation convert set observations possibly correlated variables a set values linearly uncorrelated variables called principal components ( sometimes, principal modes variation) [7]. doing pca the data got 90% variance should reduce feature dimension.[input2, eigvec, eigvalue] = pca (ds. input);cumvar = cumsum(eigvalue); //cumulative sum n(n+1)/2cumvarpercent = cumvar/cumvar(end)*100;dimensionality reductionvarious researchers statistics such mean variance iqr, etc., reduce feature dimension. researchers model using multivariate regression some fit to gaussian mixture model. here are taking mean upper diagonal variance 13*n mfcc coefficients. result is feature vector size 104.%reducing feature dimeansionmf = mean(mm,2); %row meancf = cov(mm'); % covarianceff = mf; i=0:(size(mm,1)-1) ff = [ff;diag(cf,)]; %use diagonals endt(:,end+1) = ff(:,1);classificationk-nearest neighbors (knn)principle is the data instance the same class should closer the feature space. a given data point x unknown class, can compute distance between x all data points the training data assign class determined k nearest points x.suppose are given training dataset n points.{(x1,y1),(x2,y2)(xn,yn)} where (xi,yi) represents data pair .xi- feature vectoryi- target class a data point x most likely class is determined finding distance all training data points (euclidian distance). output class be class k nearest neighbors belongs . k is predefined integer (k=1, k=2, k=3.)logistic regressionlogistic regression is of widely used classification algorithm. algorithm is used medical well business fields analytics classification. model has hypothesis function 0 h (x) 1. where h(x) = 11 + e-txcalled sigmoid logistic function. binary class classificationy {0, 1}. output this classifier be probability the given input belonging class 1. ifh(x)outputs 0.7 means the given input has 70% chance belonging class 1. since have 10 genre classes y {0, 1 .. 9} used -vs- method classification.python package mysvm developed python package called mysvm contains three modules: features, svm, acc. are used the web application feature extraction finding genre. package contains many functions do complicated feature extraction classification. acc.py data   classifier_10class.pkl   classifier_10class_prob.pkl   cmpr.pkl   xall.npy feature.py __init__.py svm.pyfeature module is used extract mfcc features a given file. contains following functions.extract (file):extract features a given file. files other formats are converted .wav format. returns numpy array.extract_all (audio_dir):extracts features all files a directory.extract_ratio (train_ratio, test_ratio, audio_dir) :extract features all files a directory a ratio. returns numpy arrays.geny(n):generates y values n classes. returns numpy array.gen_suby(sub, n):generates y values a subset classes. returns numpy array.gen_labels( ):returns list all genre labels.flattern( x) :flatterns numpy array.svm support vector machine (svm) is discriminative classifier formally defined a separating hyperplane. other words, given labeled training data (supervised learning), algorithm outputs optimal hyperplane categorizes examples. module contains various functions classification using support vector machines.poly(x,y):trains poly kernel svm fitting x, y dataset. returns trained poly kernel svm classifier.fit ( training_percentage, fold):randomly choose songs the dataset, train classifier. accepts parameter: train_percentage, fold; returns trained classifier.getprob (filename):find probabilities a song belongs each genre. returns dictionary mapping genre names probability a list top 3 genres is having probability more 0.15.random_cross_validation (train_percentage,fold):randomly cross validate training percentage fold. accepts parameter: train_percentage, fold;findsubclass (class_count):returns possible ways can combine classes. accepts integer class count. returns numpy array all possible combination.gen_sub_data (class_l):generate subset the dataset the given list classes. returns numpy array.fitsvm (xall, yall, class_l, train_percentage, fold):fits poly kernel svm returns accuracy. accepts parameter: train_percentage; fold; returns: classifier, accuracy.best_combinations (class_l, train_percentage, fold):finds possible combination classes the accuracy the given number classes accepts: training percentage, number folds returns: list best combination possible given class count.getgenre (filename):accepts filename returns genre label a given file.getgenremulti (filename):accepts filename returns top three genre labels based the probability.accmodule finding accuracy. ( res, test ) :compares arrays returns accuracy their match.resultsclassifiertraining accuracytesting accuracyk-nearest neighbors53%logistic regression75.778%54%svm linear kernel99%52%svm rbf kernel99%12%svm poly kernel99%64%while choosing 6 genre classes are getting accuracy 85%conclusion have tried various machine learning algorithms this project. aim is get maximum accuracy. have found our research we a maximum accuracy 65% using poly kernel svm 10 genre classes. have tried find best combination genre classes will result maximum accuracy. we choose 6 genre classes were able get accuracy 85%. chose labels the web application [classical, hip-hop, jazz, metal, pop rock] some songs can that has feature multiple genres. we also tried get multiple label outputs based the probability.licensemit, gpl v2.0. license.txt"
}