{
	"_id": "14521709",
	"site": "https://github.com/JasonKessler/scattertext",
	"title": "Scattertext: finding and show in interactive scatter plot distinguishing terms",
	"author": "blopeur",
	"date": "2017-06-13T14:09:48.103Z",
	"tags": {
		"categories": [
			"opensource",
			"nlp",
			"d3",
			"visualisation",
			"language-statistics",
			"word-cloud",
			"word-embeddings",
			"machine-learning",
			"sentiment-analysis",
			"emotion",
			"natural-language-processing",
			"nlp-apis",
			"data-science",
			"scatter-plot",
			"visualization",
			"glove",
			"word2vec",
			"text-visualization",
			"text-viz",
			"text-analysis",
			"text-mining"
		],
		"languages": [
			"python",
			"javascript",
			"html",
			"shell"
		]
	},
	"content": "readme.md scattertext 0.0.2.5.0table contentsinstallationcitationoverviewtutorialadvanced usesvisualizing query-based categorical differencesvisualizing kind term scoreexamples note chart layoutpresentations scattertext's sources tool finding distinguishing terms small--medium-sizedcorpora, presenting in sexy, interactive scatter plot non-overlapping term labels. exploratory data analysis got more fun.feel free use gitter community gitter.im/scattertext help to discuss project.installationinstall python 3.4.+ recommend using anaconda.$ pip install scattertext && python -m spacy.en.download you cannot ( don't to) install spacy, substitute nlp = spacy.en.english() lines nlp = scattertext.whitespacenlp.whitespace_nlp. note, is compatible word_similarity_explorer, the tokenization sentence boundary detectioncapabilities be low-performance regular expressions. demo_without_spacy.py an example.python 2.7 support is experimental. many things break. html outputs best chrome safari.citationjason s. kessler. scattertext: browser-based tool visualizing corpora differ. proceedings the 54th annual meeting the association computational linguistics (acl): system demonstrations. 2017.link preprint: arxiv.org/abs/1703.00565@article{kessler2017scattertext, author = {kessler, jason s.}, title = {scattertext: browser-based tool visualizing corpora differ}, booktitle = {proceedings acl-2017 system demonstrations}, = {2017}, address = {vancouver, canada}, publisher = {association computational linguistics},}overview is tool 's intended visualizing words phrasesare more characteristic a category others.consider example:looking this seem overwhelming. fact, 's relatively simple visualization word during 2012 political convention. each dot corresponds a word phrase mentioned republicans democratsduring conventions. closer dot is the top the plot, more frequently was used democrats. further right dot, more word phrase was used republicans. words frequentlyused both parties, \"of\" \"the\" even \"mitt\" tend occur the upper-right-hand corner. although very lowfrequency words been hidden preserve computing resources, word neither party used, \"giraffe\" be the bottom-left-hand corner. interesting things happen close the upper-left lower-right corners. the upper-left corner,words \"auto\" ( in auto bailout) \"millionaires\" are frequently used democrats infrequently never used republicans. likewise, terms frequently used republicans infrequently democrats occupy bottom-right corner. include \"big government\" \"olympics\", referring the salt lake city olympics whichgov. romney was involved.terms are colored their association. those are more associated democrats are blue, thosemore associated republicans red.terms ( unigrams now) are characteristic the both sets documents are displayed the far-right the visualization. inspiration this visualization came dataclysm (rudder, 2014).scattertext is designed help build graphs efficiently label points them. documentation (including readme) is work progress. please the quickstart well the accompanying juypternotebooks ( this ), and poking around code tests should you good idea how things .the library covers novel effective term-importance formulas, including scaled f-score. slides 52 59 the turning unstructured content kernels ideas talk more details.tutorialhelp! don't python i still to scattertext.while should learn python fully scattertext, 've put of basicfunctionality a commandline tool. tool is installed you follow procedure layed above.run $ scattertext --help the commandline see full usage information. here's quick example how use vanilla scattertext a csv file. file needs have least columns, containing text be analyzed, another containing category. the example csv below, columns are text party, respectively. example below processes csv file, the resulting html visualization cli_demo.html.note, parameter --minimum_term_frequency=8 omit terms occur less 8times, --regex_parser indicates simple regular expression parser should used place spacy. flag --one_use_per_doc indicates term frequencyshould calculated only counting more one occurrence a term a document.$ curl -s https://cdn.rawgit.com/jasonkessler/scattertext/master/scattertext/data/political_data.csv | head -2party,speaker,textdemocrat,barack obama,\"thank . thank . thank . thank so much.thank .thank so much. thank . thank very much, everybody. thank .$$ scattertext --datafile=https://cdn.rawgit.com/jasonkessler/scattertext/master/scattertext/data/political_data.csv \\> --text_column=text --category_column=party --metadata_column=speaker --positive_category=democrat \\> --category_display_name=democratic --not_category_display_name=republican --minimum_term_frequency=8 \\> --one_use_per_doc --regex_parser --outputfile=cli_demo.htmlusing scattertext a text analysis library: finding characteristic terms their associations following code creates stand-alone html file analyzes wordsused democrats republicans the 2012 party conventions, outputs notableterm associations., import scattertext spacy.>>> import scattertext st>>> import spacy>>> pprint import pprintnext, assemble data want analyze a pandas data frame. should at least columns, text 'd to analyze, the category 'd tostudy. here, text column contains convention speeches while party columncontains party the speaker. 'll eventually the speaker column label snippets the visualization.>>> convention_df = st.samplecorpora.conventiondata2012.get_data() >>> convention_df.iloc[0]party democratspeaker barack obamatext thank . thank . thank . thank so ...name: 0, dtype: objectturn data frame a scattertext corpus begin analyzing . to for differences parties, set category_col parameter 'party', use speeches,present the text column, the texts analyze setting text colparameter. finally, pass spacy model to nlp argument call build() construct corpus.# turn into scattertext corpus >>> nlp = spacy.en.english()>>> corpus = st.corpusfrompandas(convention_df, ... category_col='party', ... text_col='text',... nlp=nlp).build()let's characteristic terms the corpus, terms are associated democrats republicans. slides52 59 the turning unstructured content ot kernels ideas talk more details these approaches.here are terms differentiate corpus a general english corpus.>>> print(list(corpus.get_scaled_f_scores_vs_background().index[:10]))['obama', 'romney', 'barack', 'mitt', 'obamacare', 'biden', 'romneys', 'hardworking', 'bailouts', 'autoworkers']here are terms are associated democrats:>>> term_freq_df = corpus.get_term_freq_df()>>> term_freq_df['democratic score'] = \\... corpus.get_scaled_f_scores('democrat')>>> pprint(list(term_freq_df.sort_values(='democratic score', ... ascending=false).index[:10]))['auto', 'america forward', 'auto industry', 'insurance companies', 'pell', 'last week', 'pell grants', \"women 's\", 'platform', 'millionaires'] republicans:>>> term_freq_df['republican score'] = \\... corpus.get_scaled_f_scores('republican')>>> pprint(list(term_freq_df.sort_values(='democratic score', ... ascending=false).index[:10]))['big government', \"n't build\", 'mitt was', ' constitution', ' wanted', 'hands ', 'of mitt', '16 trillion', 'turned around', ' florida']visualizing term associations, let's write scatter plot stand-alone html file. 'll the y-axis category \"democrat\", name category \"democrat\" a capital \"d\" presentationpurposes. 'll name other category \"republican\" a capital \"r\". documents the corpus without category \"democrat\" be considered republican. set width the visualization pixels, labeleach excerpt the speaker using metadata parameter. finally, write visualization an html file.>>> html = st.produce_scattertext_explorer(corpus,... category='democrat',... category_name='democratic',... not_category_name='republican',... width_in_pixels=1000,... metadata=convention_df['speaker'])>>> open(\"convention-visualization.html\", 'wb').write(html.encode('utf-8'))below is the webpage looks . click and wait few minutes the interactive version.visualizing empath topics categories order visualize empath (fast 2016) topics categories instead terms, 'll need create corpus extracted topics categories rather unigrams bigrams. do , use featsonlyfromempath feature extractor. the source code examples how make own. creating visualization, pass use_non_text_features=true argument produce_scattertext_explorer. will instruct to the labeled empathtopics categories instead looking terms. since documents returned a topic category label is clicked be order the document-levelcategory-association strength, setting use_full_doc=true makes sense, unless haveenormous documents. otherwise, first 300 characters be shown.>>> corpus = st.corpusfromparseddocuments(convention_df,... category_col='party',... feats_from_spacy_doc=st.featsfromonlyempath(),... parsed_col='text').build()>>> html = st.produce_scattertext_explorer(corpus,... category='democrat',... category_name='democratic',... not_category_name='republican',... width_in_pixels=1000,... metadata=convention_df['speaker'],... use_non_text_features=true,... use_full_doc=true)>>> open(\"convention-visualization-empath.html\", 'wb').write(html.encode('utf-8'))advanced usesvisualizing query-based categorical differencesword representations recently become hot topic nlp. while lots work has been done visualizing terms relate one another given scores(e.g., http://projector.tensorflow.org/),none my knowledge has been done visualizing we use to examine document categories differ. this example given query term, \"jobs\", can how republicans democrats talk it differently. this configuration scattertext, words are colored their similarity a query phrase. is done using spacy-provided glove word vectors (trained the common crawl corpus). cosine distance between vectors is used, mean vectors used phrases. calculation the similar terms associated each category is simple heuristic. ,sets terms closely associated a category are found. second, terms are rankedbased their similarity the query, the top rank terms are displayed the right thescatterplot. term is considered associated its p-value is less 0.05. p-values aredetermined using monroe et al. (2008)'s difference the weighted log-odds-ratios anuninformative dirichlet prior. is only model-based method discussed monroe et al. does rely a large, -domain background corpus. since are scoringbigrams addition the unigrams scored monroe, size the corpus have be larger have high enough bigram counts proper penalization. functionrelies dirichlet distribution's parameter alpha, vector, is uniformly set 0.01.here is scattertext produce such visualization.>>> scattertext word_similarity_explorer>>> html = word_similarity_explorer(corpus,... category='democrat',... category_name='democratic',... not_category_name='republican',... target_term='jobs',... minimum_term_frequency=5,... pmi_filter_thresold=4,... width_in_pixels=1000,... metadata=convention_df['speaker'],... alpha=0.01,... max_p_val=0.05,... save_svg_button=true)>>> open(\"convention-visualization-jobs.html\", 'wb').write(html.encode('utf-8'))visualizing kind term score can scattertext visualize alternative types word scores, ensure 0 scores are greyed . use sparse_explroer function acomplish , and its source code more details.>>> sklearn.linear_model import lasso>>> scattertext sparse_explorer>>> html = sparse_explorer(corpus,... category='democrat',... category_name='democratic',... not_category_name='republican',... scores = corpus.get_regression_coefs('democrat', lasso(max_iter=10000)),... minimum_term_frequency=5,... pmi_filter_thresold=4,... width_in_pixels=1000,... metadata=convention_df['speaker'])>>> open('./convention-visualization-sparse.html', 'wb').write(html.encode('utf-8'))examples how scattertext be used subjectivity lexicon development ( why using log-axis scales are bad idea) check the subjective vs. objective notebook.scattertext also used visualize topic models, analyze word vectors categories interact, understand document classification models. can examples all these applied 2016 presidential debate transcripts. use task predicting movie's revenue the content its reviews an example tuning scattertext. the analysis movie reviews revenue. note chart layoutcozy: collection synthesizer (loncaric 2016) was used help determine terms be labeled without overlapping circle another label. automatically built data structure efficiently store query locations each circle labeled term. script build rectangle-holder.js wasfields ax1 : long, ay1 : long, ax2 : long, ay2 : longassume ax1 < ax2 ay1 < ay2query findmatchingrectangles(bx1 : long, by1 : long, bx2 : long, by2 : long) assume bx1 < bx2 by1 < by2 ax1 < bx2 ax2 > bx1 ay1 < by2 ay2 > by1 it was called using$ python2.7 src/main.py <script file name> --enable-volume-trees \\ --js-class rectangleholder --enable-hamt --enable-arrays --js rectangle_holder.jspresentations scattertextscattertext: tool visualizing differences languageturning unstructured content kernels ideas an introduction the metrics algorithms used.'s 0.0.2.5.0enhanced visualization query-based categorical differences, .k. the word_similarity_explorerfunction. run, plot is produced contains category associated termscolored either red blue hues, terms associated either classcolored greyscale slightly smaller. intensity each color indicatesassociation the query term. example:0.0.2.4.6 minor bug fixes, added minimum_not_category_term_frequency parameter. fixes problem visualizing imbalanced datasets. sets minimum number times word does appear the targetcategory must appear before is displayed.added termdocmatrix.remove_entity_tags method remove entity type tags the analysis.0.0.2.4.5fixed matched snippet displaying issue #9, fixed python 2 issue created visualization using parsedcorpus prepared via corpusfromparseddocuments, mentioned the latter part the issue #8 discussion.again, python 2 is supported experimental mode .0.0.2.4.4corrected example links this readme.fixed bug issue 8 where html visualization produced produce_scattertext_html fail.0.0.2.4.2fixed couple issues rendered scattertext broken python 2. chinese processing still does work.note: python 3.4+ you .0.0.2.4.1fixed links readme, made regex nlp available cli.0.0.2.4added command line tool, fixed bug related empath visualizations.0.0.2.3ability see a particular term is discussed differently between categoriesthrough word_similarity_explorer function.specialized mode view sparse term scores.fixed bug was caused repeated values background unigram counts.added true alphabetical term sorting visualizations.added optional save--svg button.0.0.2.2addition option showing characteristic terms ( the full set documents) being considered. option (show_characteristic produce_scattertext_explorer) is by default, currently unavailable chinese. you of good chinese wordcount list,please let know. algorithm used produce is f-score. this the following slide more details0.0.2.1.5added document word count statistics main visualization.0.0.2.1.4added preliminary support visualizing empath (fast 2016) topics categories instead emotions. the tutorial more information.0.0.2.1.3improved term-labeling.0.0.2.1.1addition strip_final_period param featsfromspacydoc deal spacytokenization all-caps documents can leave periods the end terms.0.0.2.1.0've added support chinese, including chinesenlp class, uses regexp-basedsentence splitter jieba wordsegmentation. use , see demo_chinese.py file. note corpusfrompandascurrently does support chinesenlp. order the visualization work, set chinese_mode flat true produce_scattertext_explorer.sources2012 convention data: scraped the york times.count_1w: peter norvig assembled file (downloaded norvig.com). http://norvig.com/ngrams/ an explanation how was gathered a very large corpus.hamlet.txt: william shakespeare. shapespeare.mit.eduinspiration text scatter plots: rudder, christian. dataclysm: we are ( we no 's looking). random house incorporated, 2014.loncaric, calvin. \"cozy: synthesizing collection data structures.\" proceedings the 2016 24th acm sigsoft international symposium foundations software engineering. acm, 2016.fast, ethan, binbin chen, michael s. bernstein. \"empath: understanding topic signals large-scale text.\" proceedings the 2016 chi conference human factors computing systems. acm, 2016.burt l. monroe, michael p. colaresi, kevin m. quinn. 2008. fightin words: lexical feature selection evaluation identifying content political conflict. political analysis."
}