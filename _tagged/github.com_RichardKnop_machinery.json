{
	"_id": "14342567",
	"site": "https://github.com/RichardKnop/machinery",
	"title": " Machinery â€“ asynchronous task queue (Golang implementation of Celery)",
	"author": "richardknop",
	"date": "2017-06-13T13:08:16.824Z",
	"tags": {
		"categories": [
			"opensource",
			"go",
			"golang",
			"task",
			"task-scheduler",
			"queue",
			"amqp",
			"rabbitmq",
			"redis",
			"memcached",
			"mongodb"
		],
		"languages": [
			"go",
			"makefile"
		]
	},
	"content": "readme.md machinerymachinery is asynchronous task queue/job queue based distributed message passing. stepsconfigurationcustom loggerserverworkerstasksregistering taskssignaturessupported typessending tasksdelayed tasksretry tasks pending taskskeeping resultsworkflowsgroupschordschainsdevelopmentrequirementsdependenciestesting stepsadd machinery library your $gopath/src: get github.com/richardknop/machinery/v1, you need define tasks. at sample tasks example/tasks/tasks. to a few examples.second, will need launch worker process: run example/machinery. workerfinally, once have worker running waiting tasks consume, send tasks: run example/machinery. send will able see tasks being processed asynchronously the worker:configuration config package has convenience methods loading configuration environment variables a yaml file. example, load configuration environment variables:cnf := config.newfromenvironment(true, true) load yaml file:cnf := config.newfromfile(\"config.yml\", true, true) first boolean flag signals whether configuration must loaded successfully least time. second flag enables live reloading configuration every 10 seconds.machinery configuration is encapsulated a config struct injected a dependency objects need .broker message broker. currently supported brokers are:amqp amqp url the format:amqp://[username:password@]@host[:port] example:amqp://guest:guest@localhost:5672redis redis url one these formats:redis://[password@]host[port][/db_num]redis+socket://[password@]/path//file.sock[:/db_num] example:redis://127.0.0.1:6379, with password redis://password@127.0.0.1:6379redis+socket://password@/path//file.sock:/0defaultqueuedefault queue name, e.g. machinery_tasks.resultbackendresult backend use keeping task states results.currently supported backends are:redis redis url one these formats:redis://[password@]host[port][/db_num]redis+socket://[password@]/path//file.sock[:/db_num] example:redis://127.0.0.1:6379, with password redis://password@127.0.0.1:6379redis+socket://password@/path//file.sock:/0memcache memcache url the format:memcache://host1[:port1][,host2[:port2],...[,hostn[:portn]]] example:memcache://127.0.0.1:11211 a single instance, memcache://10.0.0.1:11211,10.0.0.2:11211 a clusteramqp amqp url the format:amqp://[username:password@]@host[:port] example:amqp://guest:guest@localhost:5672keep mind amqp is recommended a result backend. keeping resultsmongodb mongodb url the format:mongodb://[username:password@]host1[:port1][,host2[:port2],...[,hostn[:portn]]][/[database][?options]] example:mongodb://127.0.0.1:27017/taskresults mongodb docs more information.resultsexpirein long store task results in seconds. defaults 3600 (1 hour).amqprabbitmq related configuration. neccessarry you are using broker/backend.exchange: exchange name, e.g. machinery_exchangeexchangetype: exchange type, e.g. directqueuebindingarguments: optional map additional arguments used binding an amqp queuebindingkey: queue is bind the exchange this key, e.g. machinery_taskprefetchcount: many tasks prefetch (set 1 you long running tasks)custom logger can define custom logger implementing following interface:type interface interface { print(...interface{}) printf(string, ...interface{}) println(...interface{}) fatal(...interface{}) fatalf(string, ...interface{}) fatalln(...interface{}) panic(...interface{}) panicf(string, ...interface{}) panicln(...interface{})} just set logger your setup code calling set function exported github.com/richardknop/machinery/v1/log package:log.set(mycustomlogger)server machinery library must instantiated before . the this is done is creating server instance. server is base object stores machinery configuration registered tasks. e.g.:import ( \"github.com/richardknop/machinery/v1/config\" \"github.com/richardknop/machinery/v1\")var cnf = config.config{ broker: \"amqp://guest:guest@localhost:5672/\", resultbackend: \"amqp://guest:guest@localhost:5672/\", maxworkerinstances: 0, amqp: config.amqpconfig{ exchange: \"machinery_exchange\", exchangetype: \"direct\", defaultqueue: \"machinery_tasks\", bindingkey: \"machinery_task\", },}server, err := machinery.newserver(&cnf) err != nil { // something the error}workers order consume tasks, need have or more workers running. you need run worker is server instance registered tasks. e.g.:worker := server.newworker(\"worker_name\")err := worker.launch() err != nil { // something the error}each worker only consume registered tasks. each task the queue worker.process() method will run a goroutine. the maxworkerinstances config option limit number concurrently running worker.process()calls (per worker). maxworkerinstances = 1 serialize task execution. maxworkerinstances = 0 makes number concurrently executed tasks unlimited (default).taskstasks are building block machinery applications. task is function defines happens a worker receives message.each task needs return error a last return value. addition error tasks now return number arguments.examples valid tasks:func add(args ...int64) (int64, error) { sum := int64(0) _, arg := range args { sum += arg } return sum, nil}func multiply(args ...int64) (int64, error) { sum := int64(1) _, arg := range args { sum *= arg } return sum, nil}// can context.context first argument tasks, useful open tracingfunc taskwithcontext(ctx context.context, arg arg) error { // ... ctx ... return nil}// tasks need return least error a minimal requirementfunc dummytask(arg string) error { return errors.(arg)}// can return multiple results the taskfunc dummytask2(arg1, arg2 string) (string, string error) { return arg1, arg2, nil}registering tasksbefore workers consume task, need register with server. is done assigning task unique name:server.registertasks(map[string]interface{}{ \"add\": add, \"multiply\": multiply,})tasks also registered by :server.registertask(\"add\", add)server.registertask(\"multiply\", multiply)simply put, a worker receives message this:{ \"uuid\": \"48760a1a-8576-4536-973b-da09048c2ac5\", \"name\": \"add\", \"routingkey\": \"\", \"eta\": null, \"groupuuid\": \"\", \"grouptaskcount\": 0, \"args\": [ { \"type\": \"int64\", \"value\": 1, }, { \"type\": \"int64\", \"value\": 1, } ], \"immutable\": false, \"retrycount\": 0, \"retrytimeout\": 0, \"onsuccess\": null, \"onerror\": null, \"chordcallback\": null} will call add(1, 1). each task should return error well we handle failures.ideally, tasks should idempotent means will no unintended consequences a task is called multiple times the same arguments.signatures signature wraps calling arguments, execution options (such immutability) success/error callbacks a task it be sent across wire workers. task signatures implement simple interface:// arg represents single argument passed invocation fo tasktype arg struct { type string value interface{}}// headers represents headers should used direct tasktype headers map[string]interface{}// signature represents single task invocationtype signature struct { uuid string name string routingkey string eta *.time groupuuid string grouptaskcount int args []arg headers headers immutable bool retrycount int retrytimeout int onsuccess []*signature onerror []*signature chordcallback *signature}uuid is unique id a task. can either set yourself it be automatically generated.name is unique task name which is registered against server instance.routingkey is used routing task correct queue. you leave empty, default behaviour be set to default queue's binding key direct exchange type to default queue name other exchange types.eta is timestamp used delaying task. it's nil, task be published workers consume immediately. it is set, task be delayed until eta timestamp.groupuuid, grouptaskcount are useful creating groups tasks.args is list arguments will passed the task it is executed a worker.headers is list headers will used publishing task amqp queue.immutable is flag defines whether result the executed task be modified not. is important onsuccess callbacks. immutable task not pass result its success callbacks while mutable task prepend result args sent callback tasks. long story short, set immutable false you to pass result the task a chain the second task.retrycount specifies many times failed task should retried (defaults 0). retry attempts be spaced in , after each failure another attempt be scheduled further the future.retrytimeout specifies long wait before resending task the queue retry attempt. default behaviour is use fibonacci sequence increase timeout each failed retry attempt.onsuccess defines tasks will called the task has executed successfully. is slice task signature structs.onerror defines tasks will called the task execution fails. first argument passed error callbacks be error string returned the failed task.chordcallback is used create callback a group tasks.supported typesmachinery encodes tasks json before sending to broker. task results are stored the backend json encoded strings. therefor types native json representation be supported. currently supported types are:boolintint8int16int32int64uintuint8uint16uint32uint64float32float64stringsending taskstasks be called passing instance signature an server instance. e.g:import ( \"github.com/richardknop/machinery/v1/tasks\")signature := &tasks.signature{ name: \"add\", args: []tasks.arg{ { type: \"int64\", value: 1, }, { type: \"int64\", value: 1, }, },}asyncresult, err := server.sendtask(signature) err != nil { // failed send task // something the error}delayed tasks can delay task setting eta timestamp field the task signature.// delay task 5 secondseta := .now().utc().add(.second * 5)signature.eta = &etaretry tasks can set number retry attempts before declaring task failed. fibonacci sequence be used space retry requests time.// the task fails, retry up 3 timessignature.retrycount = 3 pending taskstasks currently waiting the queue be consumed workers be inspected, e.g.:server.getbroker().getpendingtasks(\"some_queue\")currently supported redis broker.keeping results you configure result backend, task states results be persisted. possible states:const (// statepending - initial state a taskstatepending = \"pending\"// statereceived - task is received a workerstatereceived = \"received\"// statestarted - the worker starts processing taskstatestarted = \"started\"// stateretry - failed task has been scheduled retrystateretry = \"retry\"// statesuccess - the task is processed successfullystatesuccess = \"success\"// statefailure - processing the task failsstatefailure = \"failure\") using amqp a result backend, task states be persisted separate queues each task. although rabbitmq scale to thousands queues, is strongly advised use better suited result backend (e.g. memcache) you are expecting run large number parallel tasks.// taskresult represents actual return value a processed tasktype taskresult struct { type string `bson:\"type\"` value interface{} `bson:\"value\"`}// taskstate represents state a tasktype taskstate struct { taskuuid string `bson:\"_id\"` state string `bson:\"state\"` results []*taskresult `bson:\"results\"` error string `bson:\"error\"`}// groupmeta stores useful metadata tasks within same group// e.g. uuids all tasks are used order check all tasks// completed successfully not thus whether trigger chord callbacktype groupmeta struct { groupuuid string `bson:\"_id\"` taskuuids []string `bson:\"task_uuids\"` chordtriggered bool `bson:\"chord_trigerred\"` lock bool `bson:\"lock\"`}taskresult represents slice return values a processed task.taskstate struct be serialized stored every a task state changes.groupmeta stores useful metadata tasks within same group. e.g. uuids all tasks are used order check all tasks completed successfully not thus whether trigger chord callback.asyncresult object allows to check the state a task:taskstate := asyncresult.getstate()fmt.printf(\"current state %v task is:\", taskstate.taskuuid)fmt.println(taskstate.state) are couple convenient methods inspect task status:asyncresult.getstate().iscompleted()asyncresult.getstate().issuccess()asyncresult.getstate().isfailure() can do synchronous blocking call wait a task result:results, err := asyncresult.(time.duration(.millisecond * 5)) err != nil { // getting result a task failed // something the error} _, result := range results { fmt.println(result.interface())}workflowsrunning single asynchronous task is fine often will to design workflow tasks be executed an orchestrated . there are couple useful functions help design workflows.groupsgroup is set tasks will executed parallel, independent each . e.g.:import ( \"github.com/richardknop/machinery/v1/tasks\" \"github.com/richardknop/machinery/v1\")signature1 := tasks.signature{ name: \"add\", args: []tasks.arg{ { type: \"int64\", value: 1, }, { type: \"int64\", value: 1, }, },}signature2 := tasks.signature{ name: \"add\", args: []tasks.arg{ { type: \"int64\", value: 5, }, { type: \"int64\", value: 5, }, },}group := tasks.newgroup(&signature1, &signature2)asyncresults, err := server.sendgroup(group) err != nil { // failed send group // something the error}sendgroup returns slice asyncresult objects. you do blocking call wait the result groups tasks: _, asyncresult := range asyncresults { results, err := asyncresult.(time.duration(.millisecond * 5)) err != nil { // getting result a task failed // something the error } _, result := range results { fmt.println(result.interface()) }}chordschord allows to define callback be executed all tasks a group finished processing, e.g.:import ( \"github.com/richardknop/machinery/v1/tasks\" \"github.com/richardknop/machinery/v1\")signature1 := tasks.signature{ name: \"add\", args: []tasks.arg{ { type: \"int64\", value: 1, }, { type: \"int64\", value: 1, }, },}signature2 := tasks.signature{ name: \"add\", args: []tasks.arg{ { type: \"int64\", value: 5, }, { type: \"int64\", value: 5, }, },}signature3 := tasks.signature{ name: \"multiply\",}group := tasks.newgroup(&signature1, &signature2)chord := tasks.newchord(group, &signature3)chordasyncresult, err := server.sendchord(chord) err != nil { // failed send chord // something the error} above example executes task1 task2 parallel, aggregates results passes to task3. therefore would end happening is:multiply(add(1, 1), add(5, 5))more explicitly:(1 + 1) * (5 + 5) = 2 * 10 = 20sendchord returns chordasyncresult follows asyncresult's interface. you do blocking call wait the result the callback:results, err := chordasyncresult.(time.duration(.millisecond * 5)) err != nil { // getting result a chord failed // something the error} _, result := range results { fmt.println(result.interface())}chainschain is simply set tasks will executed by , each successful task triggering next task the chain. e.g.:import ( \"github.com/richardknop/machinery/v1/tasks\" \"github.com/richardknop/machinery/v1\")signature1 := tasks.signature{ name: \"add\", args: []tasks.arg{ { type: \"int64\", value: 1, }, { type: \"int64\", value: 1, }, },}signature2 := tasks.signature{ name: \"add\", args: []tasks.arg{ { type: \"int64\", value: 5, }, { type: \"int64\", value: 5, }, },}signature3 := tasks.signature{ name: \"multiply\", args: []tasks.arg{ { type: \"int64\", value: 4, }, },}chain := tasks.newchain(&signature1, &signature2, &signature3)chainasyncresult, err := server.sendchain(chain) err != nil { // failed send chain // something the error} above example executes task1, task2 then task3, passing result each task the next task the chain. therefore would end happening is:multiply(add(add(1, 1), 5, 5), 4)more explicitly:((1 + 1) + (5 + 5)) * 4 = 12 * 4 = 48sendchain returns chainasyncresult follows asyncresult's interface. you do blocking call wait the result the whole chain:results, err := chainasyncresult.(time.duration(.millisecond * 5)) err != nil { // getting result a chain failed // something the error} _, result := range results { fmt.println(result.interface())}developmentrequirementsrabbitmqredis (optional)memcached (optional)mongodb (optional) os x systems, can install requirements using homebrew:brew install brew install rabbitmqbrew install redisbrew install memcachedbrew install mongodbdependenciesaccording go 1.5 vendor experiment, dependencies are stored the vendor directory. approach is called vendoring is best practice go projects lock versions dependencies order achieve reproducible builds. update dependencies during development: update-deps install dependencies: install-depstestingeasiest ( platform agnostic) to run tests is via docker-compose: ci will basically run docker-compose command:(docker-compose -f docker-compose.test.yml -p machinery_ci --build -d) && (docker logs -f machinery_sut &) && (docker wait machinery_sut)alternative approach is setup development environment your machine. order enable integration tests, will need install required services (rabbitmq, redis, memcache, mongodb) export environment variables:export amqp_url=amqp://guest:guest@localhost:5672/export redis_url=127.0.0.1:6379export memcache_url=127.0.0.1:11211export mongodb_url=127.0.0.1:27017 just run: test the environment variables are exported, test only run unit tests."
}