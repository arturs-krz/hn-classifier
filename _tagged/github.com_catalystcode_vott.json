{
	"_id": "14140897",
	"site": "https://github.com/catalystcode/vott",
	"title": " AI assisted tagging tool for generating RCNN and YOLO training data",
	"author": "nadavbar",
	"date": "2017-06-13T13:35:12.284Z",
	"tags": {
		"categories": [
			"opensource",
			"cntk",
			"video-tagging",
			"deep-learning",
			"object-detection"
		],
		"languages": [
			"javascript",
			"html",
			"css"
		]
	},
	"content": "readme.md vott: visual object tagging tool tool provides end end support generating datasets validating object detection models video image assets.end end object detection pipeline: tool supports following features: ability tag annotate image directories stand alone videos.computer-assisted tagging tracking objects videos using camshift tracking algorithm.exporting tags assets cntk yolo format training object detection model.running validating trained cntk object detection model new videos generate stronger models.table contentsinstallationtagging videotagging image directoryreviewing improving object detection modelupcoming features to contributeinstallationinstalling visual object tagging tooldownload extract app release packagerun app launching \"vott\" executable will located inside unzipped folder.installing cntk the frcnn prerequisites reviewing modelplease note installation cntk fast-rcnn dependencies are optional tagging are required cntk model review training.install cntk (note: currently tool supports full installation method (non pip) cntk).follow setup instructions the cntk fast-rcnn tutorial (note: fast-rcnn currently supports linux python version 3.4 not 3.5).configure cntk-config.json ( resides the 'esources\\app' directory the tagging tool) the following properties enable model review feature:{ \"cntkpath\" : \"{cntk path default is c:/local/cntk}\",}tagging videoselect option tag videoload mp4 video file either dragging into app clicking and selecting .configure tagging job specify settings the screenshot below:frame extraction rate: number frames tag per second videotagging region type: type bounding box tagging regionsrectangle: tag bounding boxes any dimensionsquare: tag bounding boxes auto-fixed dimensionssuggested region method: to suggest regions next frametracking: camshift track tagged regions next framecopy last frame: copy regions the next frame.enable scene change detection: detect scene changes prevent false positives tracking. (note option is slightly slower)labels: labels the tagged regions (e.g. cat, dog, horse, person)tag video frame frametagging: click drag bounding box around desired area, move resize region until fits objectselected regions appear red unselected regions appear blue .assign tag a region clicking it selecting desired tag the labeling toolbar the bottom the tagging controlclick button clear tags a given framenavigation: users navigate between video frames using buttons, left/right arrow keys, the video skip bartags are auto-saved each a frame is changedtracking: regions are tracked default until given scene changes.since camshift algorithm has known limitations, can disable tracking certain sets frames. toggle tracking and off the file menu setting, the keyboard shortcut ctrl/cmd + t.export video tags using object detection menu ctrl/cmd + enote exporting: tool reserves random 20% sample the tagged frames a test set.specify following export configuration settings:export format: framework export defaults cntkexport frames until:  far  the video  export operation  proceed     - last tagged region: exports frames  until  last frame containing tags      - last visited frame: exports frames  until  last frame  the user explicitly visited      - last frame: exports  video framesoutput directory: directory path  exporting training data    tagging image directoryselect option tag image directoryload image directory selecting .configure tagging job specify settings the screenshot below:frame extraction rate: number frames tag per second videotagging region type: type bounding box tagging regionsrectangle: tag bounding boxes any dimensionsquare: tag bounding boxes auto-fixed dimensionslabels: labels the tagged regions (e.g. cat, dog, horse, person)tag each imagetagging: click drag bounding box around desired area, move resize region until fits objectselected regions appear red unselected regions appear blue .assign tag a region clicking it selecting desired tag the labeling toolbar the bottom the tagging controlclick button clear tags a given framenavigation: users navigate between video frames using buttons, left/right arrow keys, the video skip bartags are auto-saved each a frame is changedexport image directory tags tags using object detection menu ctrl/cmd + enote exporting: tool reserves random 20% sample the tagged frames a test set.specify following export configuration settings:export format: framework export defaults cntkexport frames until:  far  the video  export operation  proceed     - last tagged region: exports frames  until  last frame containing tags      - last visited frame: exports frames  until  last frame  the user explicitly visited      - last frame: exports  video framesoutput directory: directory path  exporting training data    reviewing improving object detection modeltrain model object detection using fastrcnn note: data is already cntk format, you not to run c1_drawbboxesonimages.py c2_assignlabelstobboxes.pysince cntk does embed names the classes the model, default, module returns non descriptive names the classes, e.g. \"class_1\", \"class_2\".place json file named \"model.json\" the same directory the fast-rcnn model file the correct tag labels. format json file follows your own class names:{ \"classes\" : { \"background\" : 0, \"human\" : 1, \"cat\" : 2, \"dog\" : 3 }}load new asset the model has been trained configure new load previous tagging jobapply model new asset using ctrl/cmd + rspecify model path temporary output directory the model finishes processing, validate tags, re-export retrain repeat step 1 new assets until model performance is satisfactorysupporting additonal object detection export review formats. the latest release provide support export review formats. add new object detection format, copy interface folder use yolo cntk implementations reference.upcoming featurestagging project management to contribute are welcome send any bugs may find, suggestions, any comments.before sending anything, please over repository issues list, to sure it isn't already .you are more welcome fork repository send a pull request you feel what 've done should included."
}