{
	"_id": "14412473",
	"site": "https://github.com/arminc/terraform-ecs",
	"title": "Production ready AWS ECS with terraform",
	"author": "mochtar",
	"date": "2017-06-13T13:56:40.869Z",
	"tags": {
		"categories": [
			"opensource",
			"aws-ecs",
			"terraform",
			"terraform-modules"
		],
		"languages": [
			"hcl",
			"shell"
		]
	},
	"content": "readme.md aws ecs repository contains terraform modules creating production ready ecs aws. is ecs?ecs infrastructure awsecs terraform module to create infrastructureecs deploymentthings should ssh access the instancesecs configurationloggingecs instancesloadbalancerusing 'default'ecs deployment strategiessystem containers & custom boot commandsec2 node security updatesservice discoveryecs detect deployments failure is ecsecs stands ec2 container service is aws platform running docker containers. full documentation ecs be found here, development guide be found here. more fun read be found the hitchhiker's guide aws ecs docker understand ecs is to state obvious differences against competitors kubernetes dc/os mesos. mayor differences are ecs not run -prem that lacks advanced features. two differences either been seen weakness as strengths.aws specific can run ecs -prem it is aws service not installable software. makes easier setup maintain hosting own kubernetes mesos -prem in cloud. although is service 's the same google hosted kubernetes. why? google really offers kubernetes a saas. meaning, don't manage infrastructure while ecs actually requires slaves therefore infrastructure. difference between running own kubernetes mesos ecs is lack maintenance the master nodes ecs. are responsible allowing ec2 nodes connect ecs ecs does rest. makes ecs slave nodes replaceable allows low maintenance using standard aws ecs optimized os other building blocks autoscale etc..advanced featuresalthough misses advanced features ecs plays with aws services provide simple powerful deployments. makes learning curve less high devops teams run own infrastructure. could argue if are trying do complex stuff ecs are either making unnecessary complex ecs does fit needs.having said ecs does a possibility be used a kubernetes mesos using blox. blox is essentially set tools give more control the cluster even more advanced deployment strategies.ecs infra stated above ecs needs ec2 nodes are being used slaves run docker containers . to so need infrastructure this. here is ecs production-ready infrastructure diagram. are creating:vpc a /16 ip address range an internet gateway are choosing region a number availability zones want use. high-availability need least in every availability zone are creating private a public subnet a /24 ip address rangepublic subnet convention is 10.x.0.x 10.x.1.x etc..private subnet convention is 10.x.50.x 10.x.51.x etc.. the public subnet place nat gateway the loadbalancer private subnets are used the autoscale group places instances them create ecs cluster where instances connect terraform module be able create stated infrastructure are using terraform. allow everyone use infrastructure code, repository contains code terraform modules it be easily used others.creating big module does really a benefit modules. therefore ecs module itself consists different modules. way is easier others make changes, swap modules use pieces this repository if setting ecs.details regarding a module works why is setup is described the module itself needed.modules need be used create infrastructure. an example how use modules create working ecs cluster ecs.tf ecf.tfvars.note: need use terraform version 0.9.5 aboveconventions are conventions have every modulecontains main.tf where the terraform code is main.tf is too big create more *.tf files proper names[optional] contains outputs.tf the output parameters[optional] contains variables.tf sets required attributes grouping aws set tag \"environment\" everywhere where possiblemodule structurecreate to create working ecs cluster this repository ecs.tf ecf.tfvars.quick to create from repository is:terraform && terraform apply -input=false -var-file=ecs.tfvarsactual for creating everything using default terraform flow:terraform terraform plan -input=false -var-file=ecs.tfvarsterraform apply -input=false -var-file=ecs.tfvarsmust ssh access the instances should put ecs instances directly the internet. should allow ssh access the instances directly use bastion server that. having ssh access the acceptance environment is fine you should allow ssh access production instances. don't to any manual changes the production environment. ecs module allows to an aws ssh key be able access instances, quick usage purposes ecs.tf creates new aws ssh key. private key be found the root this repository the name 'ecs_fake_private' a method issue #1ecs configurationecs is configured using /etc/ecs/ecs.config file you see here. are important configurations this file. is ecs cluster name that can connect the cluster, should specified terraform you this be variable. other is access docker hub be able access private repositories. do safely an s3 bucket contains docker hub configuration. the ecs_config variable the ecs_instances module an example.logging the default system logs docker ecs agent should to cloudwatch configured this repository. ecs container logs be pushed cloudwatch well it is better push logs a service elasticsearch. cloudwatch does support search alerts with elasticsearch other log services can more advanced search grouping. issue #5 ecs configuration described here allows configuration additional docker log drivers be configured. example fluentd shown the ecs_logging variable the ecs_instances module. aware creating clusters one aws account cloudwatch log group collision, read info.ecs instancesnormally is one group instances configured this repository. it is possible use ecs_instances module add more groups different type instances can used different deployments. makes possible have multiple different types instances different scaling options.loadbalancer is possible use application loadbalancer the classic loadbalancer this setup. default configuration is application loadbalancer that makes more sense combination ecs. is a concept internal external facing loadbalancerusing default philosophy is the modules should provide much possible sane defaults. way using modules is possible quickly configure but still change needed. is why introduced something a name 'default' the default value some the components. another reason behind is you don't need come with names you probably might have cluster your environment.looking ecs.tf might you different impression, there configure more things needed show can done.ecs deployment strategiesecs has lot different ways deploy place task the cluster. can different placement strategies random binpack, here full documentation. besides placement strategies, is possible specify constraints, described here. constraints allow a more fine-grained placement tasks specific ec2 nodes, instance type custom attributes. ecs does have is possibility run task every ec2 node boot, 's where system containers custom boot commands comes place.system containers custom boot commands some cases, is necessary have system 'service' running does particular task, gathering metrics. is possible add os specific service booting ec2 node that means are portable. better option is have 'service' run a container run container a 'service', called system container.ecs has different deployment strategies it does have option run system container every ec2 node boot. is possible do via ecs workaround via docker.ecs workaround ecs workaround is described here running amazon ecs task every instance. basically means a task definition a custom boot script start register task ecs. is awesome it allows to the system container running ecs console. bad thing it is it does restart container it crashes. is possible create lambda listen changes/exits the system container act it. example, start again the same ec2 node. issue #2docker is possible do same thing just running docker run command ec2 node boot. make sure container keeps running tell docker restart container exit. great thing this method is it is simple you use 'errors' can caught cloudwatch alert something bad happens.note: both these methods one big flaw that is you need change launch configuration restart every ec2 node by to apply changes. of time does have be problem the system containers don't change often is still issue. is possible fix in better with blox, this introduces more complexity. it is choice between simplicity an explicit update flow advanced usage more complexity.regardless method pick will need add custom command ec2 node boot. is already available the module ecs_instances using custom_userdata variable. example docker look this:docker run \\ --name=cadvisor \\ --detach=true \\ --publish 9200:8080 \\ --publish=8080:8080 \\ --memory=\"300m\" \\ --privileged=true \\ --restart=always \\ --volume=/:/rootfs:ro \\ --volume=/cgroup:/cgroup:ro \\ --volume=/var/run:/var/run:rw \\ --volume=/sys:/sys:ro \\ --volume=/var/lib/docker:/var/lib/docker:ro \\ --log-driver=awslogs \\ --log-opt=awslogs-region=eu-west-1 \\ --log-opt=awslogs-group=cadvisor \\ --log-opt=awslogs-stream=${cluster_name}/$container_instance_id \\ google/cadvisor:v0.24.1ec2 node security updates the ec2 nodes are created us means need make sure are to date secure. is possible create own ami your own os, docker, ecs agent everything else. it is much easier use ecs optimized amis are maintained aws a secure aws linux, regular security patches, recommended versions ecs agent, docker more... know to update ec2 node can subscribe aws ecs ami updates, described here. note: can create sample module this terraform does support email protocol sns. you need perform update will need update information the ecs_instances then apply changes the cluster. will create new launch_configuration it not touch running instances. therefore need replace instances by . there are three ways do :terminating instances, this may cause disruption your application users. terminating instance new will started the launch_configurationdouble size your cluster your applications when everything is and running scale cluster down. might a costly operation you need specify protect new instances that aws auto scale does terminate new instances instead the old ones. best option is drain containers an ecs instance described here. you terminate instance without disrupting application users. can done doubling ec2 nodes instances your cluster just one doing slowly by . currently, is automated/scripted to this. issue #3service discoveryecs allows use alb elb facing internally externally allows a simple very effective service discovery. you encounter need use external tools consul etc... you should ask yourself question: am not making to complex?kubernetes mesos act a big cluster where encourage to deploy kinds things it. ecs do same it makes sense group applications domains logical groups create separate ecs clusters them. can easily done you are paying the master nodes. can still in same aws account the same vpc on separate cluster separate instances.ecs detect deployments failure deploying manually can if new container has started is stuck a start/stop loop. when deploying automatically is visible. make sure get alerted containers start failing need watch events ecs state a container has stopped. can done using module ecs_events. only thing is missing the module is actual alert. is terraform 't handle email all protocols aws_sns_topic_subscription are specific per customer."
}