{
	"_id": "14416530",
	"site": "https://github.com/tonybeltramelli/pix2code",
	"title": "Pix2code: Generating Code from a GUI Screenshot",
	"author": "visarga",
	"date": "2017-06-13T13:56:32.617Z",
	"tags": {
		"categories": [
			"opensource",
			"deep-learning",
			"datasets",
			"deep-neural-networks",
			"front-end-development",
			"graphical-user-interface"
		],
		"languages": []
	},
	"content": "readme.md pix2codegenerating code a graphical user interface screenshot video demo the system be seen here paper is available https://arxiv.org/abs/1705.07962official research page: https://uizard.io/research#pix2codeabstracttransforming graphical user interface screenshot created a designer computer code is typical task conducted a developer order build customized software, websites mobile applications. this paper, show deep learning techniques be leveraged automatically generate code given graphical user interface screenshot input. model is able generate code targeting three different platforms (.e. ios, android web-based technologies) a single input image over 77% accuracy.citation@article{beltramelli2017pix2code, title={pix2code: generating code a graphical user interface screenshot}, author={beltramelli, tony}, journal={arxiv preprint arxiv:1705.07962}, ={2017}}disclaimer following software is shared educational purposes . the author its affiliated institution are responsible any manner whatsoever any damages, including direct, indirect, special, incidental, consequential damages any character arising a result the or inability use software. project pix2code is research project demonstrating application deep neural networks generate code visual inputs. current implementation is , in way, intended, nor able generate code a real-world context. could emphasize enough this project is experimental shared educational purposes .both source code the datasets are provided foster future research machine intelligence are designed end users.faq will datasets available? datasets be made available upon publication rejection the paper the nips 2017 conference; author notification is scheduled early september 2017 the datasets be uploaded this repo during same period. will provide datasets consisting gui screenshots, associated dsl code, associated target code three different platforms (ios, android, web-based gui). the source code available? written the paper, datasets be made available nothing is said the source code. however, of unexpected amount interest this project, pix2code implementation described the paper also open-sourced this repo together the datasets. pix2code support target platforms/languages?, pix2code is a research project will stay the state described the paper consistency reasons. project is really a toy example demonstrating part the technology are building uizard technologies ( customer-ready platform is likely support target platforms/languages). are course more welcome fork repo experiment yourself other target platforms/languages. i able use pix2code my frontend project?, pix2code is experimental won't for specific cases.however, stay tuned uizard technologies, are working hard building customer-ready platform generate code gui mockups you use your projects! is model performance measured? accuracy/error reported the paper is measured the dsl level comparing each generated token each expected token. difference length between generated token sequence the expected token sequence is counted error. long does take train model? a nvidia tesla k80 gpu, takes little less 5 hours optimize 109 * 10^6 parameters one dataset; expect around 15 hours you to train model the three target platforms. am front-end developer, i soon lose job?( have genuinely been asked question multiple times)tl;dr anytime soon ai replace front-end developers. assuming mature version pix2code able generate gui code 100% accuracy every platforms/languages the universe, front-enders still needed implement logic, interactive parts, advanced graphics animations, all features users love. product are building uizard technologies is intended bridge gap between ui/ux designers front-end developers, replace of . we to rethink traditional workflow too often results more frustration innovation. want designers be creative possible better serve end users, developers dedicate time programming core functionalities forget repetitive tasks such ui implementation. believe a future where ai collaborate humans, replace humans.media coveragewired uk next web"
}