{
	"_id": "14164041",
	"site": "https://github.com/src-d/go-kallax",
	"title": " Kallax a PostgreSQL Typesafe ORM for the Go Language",
	"author": "mcuadros",
	"date": "2017-06-13T13:34:46.737Z",
	"tags": {
		"categories": [
			"opensource",
			"database",
			"postgresql",
			"postgres",
			"golang",
			"orm"
		],
		"languages": [
			"go",
			"makefile"
		]
	},
	"content": "readme.md kallax is postgresql typesafe orm the language. aims provide way programmatically write queries interact a postgresql database without having write single line sql, strings refer columns use values any type queries. that reason, first priority kallax is provide type safety the data access layer.another the goals kallax is sure models are, and foremost, structs without having use database-specific types such , for example, sql.nullint64.support arrays all basic types all json arrays operators is provided well.contentsinstallationusagedefine modelsstruct tagsprimary keysmodel constructorsmodel eventsmodel schemaautomatic schema generation migrations schemamanipulate modelsinsert modelsupdate modelssave modelsdelete modelsquery modelssimple queriesgenerated findbysquery relationshipsquerying jsontransactionscaveatsmigrationscustom operatorsdebug sql queriesbenchmarksacknowledgementscontributinginstallation recommended to install kallax is: get -u gopkg./src-d/-kallax.v1/...kallax includes binary tool used go generate,please sure $gopath/bin is your $pathusageimagine have following file the package where models are.package modelstype user struct { kallax.model `table:\"users\"` id kallax.ulid `pk:\"\"` username string email string password string} put following any file that package://:generate kallax gen all have do is run generate ./... a kallax. file be generated all generated code your model. you don't to go generate, though is preferred , you just to package run kallax gen yourself.excluding files generationsometimes might to the generated code the same package is defined cause problems during generation you regenerate models. can exclude files the package changing go:generate comment the following://:generate kallax gen -e file1. -e file2.define models model is a struct embeds kallax.model type. the fields this struct be columns the database table. model needs have (and one) primary key. is whatever field the struct the struct tag pk, can pk:\"\" a non auto-incrementable primary key pk:\"autoincr\" one is auto-incrementable.more primary keys is discussed the primary keys section., let's review rules conventions model fields: the fields basic types types implement sql.scanner driver.valuer be considered column the table their matching type.arrays slices types mentioned above be treated postgresql arrays their matching type.fields are structs ( pointers structs) interfaces implementing sql.scanner driver.valuer be considered json. same arrays slices types follow rules.fields are structs ( pointers structs) the struct tag kallax:\",inline\" are embedded be considered inline, their fields be considered if were the root the model. pointer fields are nullable default. means do need use sql.nullint64, sql.nullbool the likes kallax automatically takes care that you. warning: json sql.scanner implementors be initialized new(t) case are nil before are scanned. default, name a column be name the struct field converted lower snake case (e.g. username => user_name, userid => user_id). can override with struct tag kallax:\"my_custom_name\".slices structs ( pointers structs) are models themselves be considered 1:n relationship. arrays models are supported design. struct pointer struct field is model itself be considered 1:1 relationship. relationships, foreign key is assumed be name the model converted lower snake case plus _id (e.g. user => user_id). can override with struct tag fk:\"my_custom_fk\". inverse relationship, need use struct tag fk:\",inverse\". can combine inverse overriding foreign key fk:\"my_custom_fk,inverse\". the case inverses, foreign key name does specify name the column the relationship table, the name the column the own table. name the column the table is always primary key the model cannot changed the being.foreign keys not to in model, are automagically managed underneath kallax.kallax provides kallax.timestamps struct contains createdat updatedat will managed automatically.let's an example models all cases:type user struct { kallax.model `table:\"users\"` kallax.timestamps id int64 `pk:\"autoincr\"` username string password string emails []string // is demo purposes, please don't this // 1:n relationships load n rows default, // only it n is small. // n is big, should probably querying posts // table instead. posts []*post `fk:\"poster_id\"`}type post struct { kallax.model `table:\"posts\"` kallax.timestamps id int64 `pk:\"autoincr\"` content string `kallax:\"post_content\"` poster *user `fk:\"poster_id,inverse\"` metadata metadata `kallax:\",inline\"`}type metadata struct { metadatatype metadatatype metadata map[string]interface{} // will json}struct tagstagdescription be used table:\"table_name\"specifies name the table a model. not provided, name the table be name the struct lower snake case (e.g. userpreference => user_preference)embedded kallax.modelpk:\"\"specifies field is primary key field a valid identifier typepk:\"autoincr\"specifies field is auto-incrementable primary key field a valid identifier typekallax:\"column_name\"specifies name the column model field is a relationshipkallax:\"-\"ignores field does store any model fieldkallax:\",inline\"adds fields the struct field the model. column name also given before comma, it is ignored, since field is a column anymore struct fieldfk:\"foreign_key_name\"name the foreign key column relationship fieldfk:\",inverse\"specifies relationship is inverse relationship. foreign key name also given before comma relationship fieldprimary keysprimary key types need satisfy identifier interface. though have do , the generator is smart enough know to wrap types make easier the user. following types be used primary key:int64uuid.uuidkallax.ulid: is type kallax provides implements lexically sortable uuid. can store as uuid any uuid, internally 's ulid you be able sort lexically it. you need another type primary key, feel free open pull request implementing .known limitations one primary key be specified it 't a composite key.model constructorskallax generates constructor your type named {typename}. you customize by implementing private constructor named {typename}. constructor generated kallax use same signature private constructor has. can this provide default values construct model some values. you implement constructor:func newuser(username, password string, emails ...string) (*user, error) { username != \"\" || len(emails) == 0 || password != \"\" { return errors.(\"all fields are required\") } return &user{username: username, password: password, emails: emails}}kallax generate with following signature:func newuser(username string, password string, emails ...string) (*user, error)important: your primary key is auto-incrementable, should set id every model create your constructor. , at least, set before saving . inserting, updating, deleting reloading object no primary key set return error. you don't implement own constructor 's ok, kallax generate for just instantiating object this:func newt() *t { return (t)}model eventsevents be defined models they be invoked certain times the model lifecycle.beforeinsert: be called before inserting model.beforeupdate: be called before updating model.beforesave: be called before updating inserting model. 's always called before beforeinsert beforeupdate.beforedelete: be called before deleting model.afterinsert: be called inserting model. presence this event cause insertion the model run a transaction. the event returns error, will rolled .afterupdate: be called updating model. presence this event cause update the model run a transaction. the event returns error, will rolled .aftersave: be called updating inserting model. 's always called afterinsert afterupdate. presence this event cause operation the model run a transaction. the event returns error, will rolled .afterdelete: be called deleting model. presence this event cause deletion run a transaction. the event returns error, will rolled .to implement events, implement following interfaces. can implement many you :beforeinserterbeforeupdaterbeforesaverbeforedeleterafterinserterafterupdateraftersaverafterdeleterexample:func (u *user) beforesave() error { u.password == \"\" { return errors.(\"cannot save user without password\") } !iscrypted(u.password) { u.password = crypt(u.password) } return nil}kallax generated codekallax generates bunch code every single model have saves to file named kallax. in same package. every model have, kallax generate following you:internal methods your model make work kallax satisfy record interface. store named {typename}store: store is way access data. store a given type is way access manipulate data that type. can an instance the type store new{typename}store(*sql.db). query named {typename}query: query is way will able build programmatically queries perform the store. store will accept queries its own type. can create new query new{typename}query(). query contain methods adding criteria your query every field your struct, called findbys. query object is immutable, is, every condition added it, changes query. you to reuse part a query, can call copy() method a query, will return query identical the used call method. resultset named {typename}resultset: resultset is way iterate and obtain elements a resultset returned the store. store a given type always return result set the matching type, will return records that type.schema all models containing the fields. way, can access name a specific field without having use string, is, typesafe .model schemaautomatic schema generation migrationsautomatic create table models migrations is yet supported, though will probably in future releases. schema global variable schema be created your kallax., that contains field the name every your models. those are schemas your models. each model schema contains the fields that model., to access username field the user model, can accessed :schema.user.usernamemanipulate models all the following sections, will assume have store store our model's type.insert models insert model just need use insert method the store pass a model. the primary key is auto-incrementable the object does have set, insertion fail.user := newuser(\"fancy_username\", \"super_secret_password\", \"foo@email.\")err := store.insert(user) err != nil { // handle error} our model has relationships, will saved (note: saved in insert update) well. relationships the relationships not, though. relationships are saved one level depth.user := newuser(\"foo\")user.posts = append(user.posts, newpost(user, \" post\"))err := store.insert(user) err != nil { // handle error} there are relationships the model, both model the relationships be saved a transaction only succeed all them are saved correctly.update models insert model just need use update method the store pass a model. will return error the model was already persisted has an id.user := findlast()rowsupdated, err := store.update(user) err != nil { // handle error} default, a model is updated, its fields are updated. can specify fields update passing to update.rowsupdated, err := store.update(user, schema.user.username, schema.user.password) err != nil { // handle error} our model has relationships, will saved (note: saved in insert update) well. relationships the relationships not, though. relationships are saved one level depth.user := findlastposter()rowsupdated, err := store.update(user) err != nil { // handle error} there are relationships the model, both model the relationships be saved a transaction only succeed all them are saved correctly.save models save model just need use save method the store pass a model. save is a shorthand will call insert the model is yet persisted update it is.updated, err := store.save(user) err != nil { // handle error} updated { // was updated, inserted} our model has relationships, will saved well. relationships the relationships not, though. relationships are saved one level depth.user := newuser(\"foo\")user.posts = append(user.posts, newpost(user, \" post\"))updated, err := store.save(user) err != nil { // handle error} there are relationships the model, both model the relationships be saved a transaction only succeed all them are saved correctly.delete models delete model just to the delete method the store. will return error the model was already persisted.err := store.delete(user) err != nil { // handle error}relationships the model are automatically removed using delete. that, specific methods are generated the store the model. one many relationships:// remove specific postserr := store.removeposts(user, post1, post2, post3) err != nil { // handle error}// remove postserr := store.removeposts(user) one one relationships:// remove thingerr := store.removething(user)query modelssimple queries perform query have do following things:create querypass query find, findone, mustfind mustfindone the storegather results the result set, the used method was find mustfind// create queryq := newuserquery(). where(kallax.(schema.user.username, \"joe%\")). order(kallax.asc(schema.user.username)). limit(20). offset(2)rs, err := store.find(q) err != nil { // handle error} rs.next() { user, err := rs.() if err != nil { // handle error }}next automatically close result set it hits end. you to prematurely exit iteration can close manually rs.close(). can query a single row findone.q := newuserquery(). where(kallax.eq(schema.user.username, \"joe\"))user, err := store.findone(q) can get of rows a result without having manually iterate result set findall.q := newuserquery(). where(kallax.(schema.user.username, \"joe%\")). order(kallax.asc(schema.user.username)). limit(20). offset(2)users, err := store.findall(q) err != nil { // handle error} default, columns a row are retrieved. not retrieve of , you specify columns include/exclude. into account partial records retrieved the database not writable. make writable will need reload object.// select username passwordnewuserquery().select(schema.user.username, schema.user.password)// select but passwordnewuserquery().selectnot(schema.user.password)generated findbyskallax generates findby every field your model which makes sense do . what is findby? is shorthand add condition the query a specific field.consider following model:type person struct { kallax.model id int64 `pk:\"autoincr\"` name string birthdate .time age int}four findbys be generated this model:func (*personquery) findbyid(...int64) *personqueryfunc (*personquery) findbyname(string) *personqueryfunc (*personquery) findbybirthdate(kallax.scalarcond, .time) *personqueryfunc (*personquery) findbyage(kallax.scalarcond, int) *personquery way, can do following:newpersonquery(). findbyage(kallax.gtoreq, 18). findbyname(\"bobby\")instead :newpersonquery(). where(kallax.gtoreq(schema.person.age, 18)). where(kallax.eq(schema.person.name, \"bobby\"))why are three different types methods generated? primary key field is treated a special and allows multiple ids be passed, since searching multiple ids is common operation.types are often searched equality (integers, floats, times, ...) allow operator be passed them determine operator use.types can be searched value (strings, bools, ...) allow value be passed.count resultsinstead passing query find findone, can pass to count get number rows the resultset.n, err := store.count(q)query relationships default, relationships are retrieved unless query specifies .for each your relationships, method your query is created be able include relationships your query. to relationships:// select posts including user posted q := newpostquery().withposter()rs, err := store.find(q) to relationships are always included the same query. , if have 4 to relationships you them , only 1 query be done, everything be retrieved. to many relationships:// select users including posts// note: is really bad idea, all posts be loaded// the n side your 1:n relationship is big, consider querying n store// instead doing // a condition be passed the `{name}` method filter results.q := newuserquery().withposts(nil)rs, err := store.find(q) avoid n+1 problem 1:n relationships, kallax performs batching this case., a batch users are retrieved the database a single query, all posts those users finally, are merged. process is repeated until are more rows the result. of , retrieving 1:n relationships is really fast. default batch size is 50, can change using batchsize method queries .note: a filter is passed a {name} method can longer guarantee all related objects are and, therefore, retrieved records not writable.reloading model, for example, have model is writable you selected field can always reload and the full object. the object is reloaded, the changes made the object have been saved be discarded overwritten the values the database.err := store.reload(user)reload not reload relationships, the model itself. a reload model always writable.querying json can query arbitrary json using json operators defined the kallax package. schema the json ( it's struct, obviously maps is ) is generated.q := newpostquery().where(kallax.jsoncontainsanykey( schema.post.metadata, \"foo\", \"bar\",))transactions execute things a transaction transaction method the model store be used. the operations done using store provided the callback be run a transaction. the callback returns error, transaction be rolled .store.transaction(func(s *userstore) error { err := s.insert(user1); err != nil { return err } return s.insert(user2)}) fact a transaction receives store the type the model be problem you to store several models different types. kallax has method named storefrom initializes store the type want have same underlying store some .store.transaction(func(s *userstore) error { var poststore poststore kallax.storefrom(&poststore, s) _, p := range posts { err := poststore.insert(p); err != nil { return err } } return s.insert(user)})transaction be used inside transaction, it does open new , reuses existing .caveats is possible use slices arrays types are one these types:basic types (e.g. []string, []int64) (except rune, complex64 complex128)types implement sql.scanner driver.valuer reason why is possible is kallax implements support arrays all basic types hand also types implementing sql.scanner driver.valuer (using reflection this case), without having common interface operate them, arbitrary types not supported. example, consider following type type foo string, using []foo not supported. that will fail during scanning rows not code-generation for . in future, might moved a warning an error during code generation.aliases slice types are supported, though. we type strings []string, using strings be supported, a cast this ([]string)(&slice) 's supported []string is supported..time url.url need be used is. is, can use type foo being type foo .time. .time url.url are types are treated a special , if do , it be same saying type foo struct { ... } kallax no longer able identify correct type..time fields be truncated remove nanoseconds save, insert update, since postgresql not able store . postgresql stores times timezones utc internally. , times come as utc ( can local method convert back the local timezone). can change timezone will used bring times from database the postgresql configuration.multidimensional arrays slices are supported except inside json field.migrationskallax generate migrations your schema automatically, you to. is process completely separated the model generation, it does force to generate migrations using kallax.sometimes, kallax won't able infer type you want specific column type a field. can specify with sqltype struct tag a field.type model struct { kallax.model `table:\"foo\"` stuff supercustomtype `sqltype:\"bytea\"`} can the full list default type mappings between and sql.generate migrations generate migration, have run command kallax migrate.kallax migrate --input ./users/ --input ./posts/ -- ./migrations --name initial_schema migrate command accepts following flags:namerepeateddescriptiondefault--name -nname the migration file ( be converted a_snakecase_name)migration--input -iyesevery occurrence this flag specify directory which kallax models be found. can specify multiple times flag you your models scattered across several packagesrequired-- or -odestination folder where migrations be generated./migrationsevery single migration consists 2 files:timestamp_name..sql: script will upgrade database this version.timestamp_name.down.sql: script will downgrade database this version.additionally, is lock.json file where schema the last migration is store diff against current models.run migrations run migration can either kallax migrate or kallax migrate down. will upgrade database down downgrade .these are flags available up down:namedescriptiondefault--dir -ddirectory where migrations are stored./migrations--dsndatabase connection stringrequired--steps -smaximum number migrations run0--migrate the up ( available up--version -vfinal version the database want running migration. version is timestamp value the beginning migration files0 no --steps --version are provided down, will nothing. --all is provided up, will upgrade database the up. --steps --version are provided either or down will only --version, it is more specific.example:kallax migrate --dir ./-migrations --dns 'user:pass@localhost:5432/dbname?sslmode=disable' --version 1493991142type mappings typesql typekallax.uliduuidkallax.uuiduuidkallax.numericidserial primary keys, bigint foreign keysint64 primary keysserialint64 foreign keys other fieldsbigintstringtextrunechar(1)uint8smallintint8smallintbytesmallintuint16integerint16smallintuint32bigintint32integeruintnumeric(20)intbigintint64bigintuint64numeric(20)float32realfloat64doubleboolbooleanurl.urltext.timetimestamptz.durationbigint[]tt'[] * where t' is sql type type tmap[k]vjsonbstructjsonb*structjsonb other type must explicitly specified.custom operators can create custom operators kallax using newoperator newmultioperator functions.newoperator creates operator the specified format. returns function given schema field a value returns condition. format is string which :col: get replaced the schema field :arg: be replaced the value.var gt = kallax.newoperator(\":col: > :arg:\")// be used this:query.where(gt(someschemafield, 9000))newmultioperator does exactly same the previous , but accepts variable number values.var = kallax.newmultioperator(\":col: :arg:\")// be used this:query.where((someschemafield, 4, 5, 6)) function already takes care wrapping :arg: parenthesis.further customization you need further customization, can create own custom operator. need things: condition constructor ( operator itself) takes field the values create proper sql expression. tosqler yields sql expression.imagine want greater operator only works integers.func gtint(col kallax.schemafield, n int) kallax.condition { return func(schema kallax.schema) kallax.tosqler { // is very important all schemafields // are qualified using schema return &gtint{col.qualifiedname(schema), n} }}type gtint struct { col string val int}func (g *gtint) tosql() (sql string, params []interface{}, err error) { return fmt.sprintf(\"%s > ?\", g.col), []interface{}{g.val}, nil}// be used this:query.where(gtint(someschemafield, 9000)) most the operators, newoperator newmultioperator are enough, the usage these functions is preferred the completely custom approach. it if is other to build custom operator.debug sql queries is possible debug sql queries being executed kallax. do , you need call debug method a store. returns new store debugging enabled.store.debug().find(myquery) will log stdout using log.printf kallax: query: query sql statement, args: [arg1 arg2]. can a custom logger ( function a type func(string, ...interface{}) using debugwith method instead.func mylogger(message string, args ...interface{}) { myloglib.debugf(\"%s, args: %v\", message, args)}store.debugwith(mylogger).find(myquery)benchmarkshere are benchmarks against gorm, sqlboiler database/sql. the future might add benchmarks some more complex cases other available orms.benchmarkkallaxinsertwithrelationships-4 200 5530403 ns/op 19680 b/op 454 allocs/opbenchmarksqlboilerinsertwithrelationships-4 100 18822064 ns/op 5896 b/op 185 allocs/opbenchmarkrawsqlinsertwithrelationships-4 200 5124398 ns/op 4516 b/op 127 allocs/opbenchmarkgorminsertwithrelationships-4 200 5627979 ns/op 35070 b/op 610 allocs/opbenchmarkkallaxinsert-4 300 4084723 ns/op 3722 b/op 88 allocs/opbenchmarksqlboilerinsert-4 300 4355927 ns/op 1152 b/op 35 allocs/opbenchmarkrawsqlinsert-4 300 4153576 ns/op 1053 b/op 27 allocs/opbenchmarkgorminsert-4 300 4538285 ns/op 4681 b/op 107 allocs/opbenchmarkkallaxqueryrelationships/query-4 1000 1632464 ns/op 59672 b/op 1569 allocs/opbenchmarksqlboilerqueryrelationships/query-4 500 2185274 ns/op 125577 b/op 5098 allocs/opbenchmarkrawsqlqueryrelationships/query-4 20 54735535 ns/op 217376 b/op 6624 allocs/opbenchmarkgormqueryrelationships/query-4 300 4750212 ns/op 1069088 b/op 20833 allocs/opbenchmarkkallaxquery/query-4 3000 512827 ns/op 50672 b/op 1590 allocs/opbenchmarksqlboilerquery/query-4 2000 701642 ns/op 54079 b/op 2436 allocs/opbenchmarkrawsqlquery/query-4 3000 488037 ns/op 37480 b/op 1525 allocs/opbenchmarkgormquery/query-4 1000 1413357 ns/op 427403 b/op 7068 allocs/oppassok gopkg./src-d/-kallax.v1/benchmarks40.485s we see the benchmark, performance loss is very much compared raw database/sql, while gorms performance loss is very big the memory consumption is higher. sqlboiler, the hand, has lower memory footprint kallax, a bigger performance loss (though very significant most cases).source code the benchmarks be found the benchmarks folder.notes:benchmarks were run a 2015 macbook pro i5 8gb ram 128gb ssd hard drive running fedora 25.benchmark database/sql querying relationships is implemented a very naive 1+n solution. 's why result is bad.acknowledgementsbig thank to masterminds/squirrel library, is awesome query builder used internally this orm.lib/pq, golang postgresql driver ships a ton support builtin types.mattes/migrate, golang library manage database migrations.contributingreporting bugskallax is code generation tool, it obviously has been tested all possible types cases. you find case where code generation is broken, please report issue providing minimal snippet us be able reproduce issue fix .suggesting featureskallax is very opinionated orm works us, changes make things work us add complexity via configuration not considered adding. we decide to implement feature 're suggesting, keep mind it might be it is a idea, because does work us is aligned the direction want kallax be moving forward.running tests obvious reasons, instance postgresql is required run tests this package. default, assumes an instance exists 0.0.0.0:5432 an user, password database name equal testing. that is the case can set following environment variables:dbname: name the databasedbuser: database userdbpass: database user passwordlicensemit, license"
}