{
	"_id": "14372234",
	"site": "https://github.com/kmather73/NotHotdog-Classifier",
	"title": "I Build My Own Not-Hotdog Classifier from HBO's Silicon Valley",
	"author": "kmather73",
	"date": "2017-06-13T13:57:06.896Z",
	"tags": {
		"categories": [
			"opensource"
		],
		"languages": [
			"jupyter notebook",
			"python"
		]
	},
	"content": "readme.md nothotdog-classifier you watch hbo's silicon valley? i and was inspired mr. jian-yang make own hotdog classifier\" would say i told there is app the market tell if have hotdog not hotdog. is very and do want work it more. can hire someone else.\" - jian-yang , 2017here is demonstration the final version the product we are going be makingclick step 1: collecting data very step making classifier is collect data. thus need find images hotdogs not-hotdogs. best do is you are professor stanford you each your student assignment collect images food you, be warned they might try steal idea you.click so you're a professor stanford will need collect data yourself :( since 'm a professor stanford had collect images myself. do i used imagenet search my images, since imagenet is a database images. find hotdog images just searched hotdog, chili dog frankfurter downloading of images would about 1857 hotdog images. the -hotdog images searched food, furniture, and pets give about 4024 -hotdog images. to actually download images need get urls, do i need click the tab download tab click link called urls copy url the page on will in script we'll write download of images.next need write scripts download save of images, here is python code saving imageshere function store_raw_images takes a list folders names where want save images from each the links.def store_raw_images(folders, links): pic_num = 1 link, folder zip(links, folders): not os.path.exists(folder): os.makedirs(folder) image_urls = str(urllib.request.urlopen(link).read()) i image_urls.split('\\'): try: urllib.request.urlretrieve(, folder+\"/\"+str(pic_num)+\".jpg\") img = cv2.imread(folder+\"/\"+str(pic_num)+\".jpg\") # preprocessing you if img is none: // more stuff here you cv2.imwrite(folder+\"/\"+str(pic_num)+\".jpg\",img) pic_num += 1 except exception e: print(str(e)) next have main method drive codedef main(): links = [ 'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n01318894', \\ 'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n03405725', \\ 'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n07942152', \\ 'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n00021265', \\ 'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n07690019', \\ 'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n07865105', \\ 'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n07697537' ] paths = ['pets', 'furniture', '', 'food', 'frankfurter', 'chili-dog', 'hotdog'] store_raw_images(paths, links) just wait it download of thoses hotdogs!!!step 2: cleaning data this point have collected data we need clean up bit. you a at data will probably notice there are garbage images we need remove, images look one the following do let write more scripts do work us, we need get copy the images we to remove place in folder called invalid.def removeinvalid(dirpaths): dirpath dirpaths: img os.listdir(dirpath): invalid os.listdir('invalid'): try: current_image_path = str(dirpath)+'/'+str(img) invalid = cv2.imread('invalid/'+str(invalid)) question = cv2.imread(current_image_path) invalid.shape == question.shape not(np.bitwise_xor(invalid,question).()): os.remove(current_image_path) break except exception e: print(str(e)) just check folder 'food' and remove images might like hotdog. next made folders called \"hotdog\" \"not-hotdog\" placed 'frankfurter', 'chili-dog', 'hotdog' folders the \"-hotdog\" the 'frankfurter', 'chili-dog', 'hotdog' folders the 'hotdog' folder.step 3: preprocessing data augmentationbefore can feed data train neural net first need do data normalization some data augmentation. turns that don't an equal number hotdog not hotdog images is problem training classifier. fix problem can some data augment sampling images each the class applying random rotation blur the image get more data. method be used greatly increase amount data have since neural nets need large amount data get results. used method get 15000 images each classdef rotateimage(img, angle): (rows, cols, ch) = img.shape m = cv2.getrotationmatrix2d((cols/2,rows/2), angle, 1) return cv2.warpaffine(img, m, (cols,rows)) def loadblurimg(path, imgsize): img = cv2.imread(path) angle = np.random.randint(0, 360) img = rotateimage(img, angle) img = cv2.blur(img,(5,5)) img = cv2.resize(img, imgsize) return imgdef loadimgclass(classpath, classlable, classsize, imgsize): x = [] y = [] path classpath: img = loadblurimg(path, imgsize) x.append(img) y.append(classlable) while len(x) < classsize: randidx = np.random.randint(0, len(classpath)) img = loadblurimg(classpath[randidx], imgsize) x.append(img) y.append(classlable) return x, ydef loaddata(img_size, classsize): hotdogs = glob.glob('./hotdog/**/*.jpg', recursive=true) nothotdogs = glob.glob('./-hotdog/**/*.jpg', recursive=true) imgsize = (img_size, img_size) xhotdog, yhotdog = loadimgclass(hotdogs, 0, classsize, imgsize) xnothotdog, ynothotdog = loadimgclass(nothotdogs, 1, classsize, imgsize) print(\" are\", len(xhotdog), \"hotdog images\") print(\" are\", len(xnothotdog), \" hotdog images\") x = np.array(xhotdog + xnothotdog) y = np.array(yhotdog + ynothotdog) return x, y normalize images convert to gray scale then preform histogram equalizationdef togray(images): # rgb2gray converts rgb values grayscale values forming weighted sum the r, g, b components: # 0.2989 * r + 0.5870 * g + 0.1140 * b # source: https://www.mathworks.com/help/matlab/ref/rgb2gray.html images = 0.2989*images[:,:,:,0] + 0.5870*images[:,:,:,1] + 0.1140*images[:,:,:,2] return imagesdef normalizeimages(images): # histogram equalization get better range # source http://scikit-image.org/docs/dev/api/skimage.exposure.html#skimage.exposure.equalize_hist images = (images / 255.).astype(np.float32) i range(images.shape[0]): images[] = exposure.equalize_hist(images[]) images = images.reshape(images.shape + (1,)) return imagesdef preprocessdata(images): grayimages = togray(images) return normalizeimages(grayimages)step 4: building neural net model is convolutional neural networks three convolutional layers followed two fully connected layers. based the cnn the steering angle model building self-driving cars built comma.ai. if good enough drive car 's enough detect hotdog. model includes elu layers dropout introduce nonlinearity:layerdescriptioninput128x128x1 gray scale imageconvolution 8x84x4 subsamplingeluconvolution 5x52x2 subsamplingeluconvolution 5x52x2 subsamplingflattendropout.2 dropout probabilityelufully connectedoutput 512dropout.5 dropout probabilityelufully connectedoutput 2softmaxoutput 2 actually code up will a library called keras is built top tensorflowdef kerasmodel(inputshape): model = sequential() model.add(convolution2d(16, 8, 8, subsample=(4, 4),border_mode='valid', input_shape=inputshape)) model.add(elu()) model.add(convolution2d(32, 5, 5, subsample=(2, 2), border_mode=\"same\")) model.add(elu()) model.add(convolution2d(64, 5, 5, subsample=(2, 2), border_mode=\"same\")) model.add(flatten()) model.add(dropout(.2)) model.add(elu()) model.add(dense(512)) model.add(dropout(.5)) model.add(elu()) model.add(dense(2)) model.add(activation('softmax')) return modelstep 5: training neural net train network split data a tranining set a test setrand_state = np.random.randint(0, 100)x_train, x_test, y_train, y_test = train_test_split(scaled_x, y, test_size=0.2, random_state=rand_state) is simple traininputshape = (128, 128, 1)model = kerasmodel(inputshape)model.compile('adam', 'categorical_crossentropy', ['accuracy'])history = model.fit(x_train, y_train, nb_epoch=10, validation_split=0.1)step 6: results test model the test set just metrics = model.evaluate(x_test, y_test) metric_i range(len(model.metrics_names)): metric_name = model.metrics_names[metric_i] metric_value = metrics[metric_i] print('{}: {}'.format(metric_name, metric_value)) find we very results 98% accuracy. would jian-yang proud.step 7: profit that are done can sell to periscope become very richclick"
}