{
	"_id": "14475884",
	"site": "https://github.com/leandromoreira/digital_video_introduction",
	"title": "A hands-on introduction to video technology: image, video, codec and more",
	"author": "manorwar8",
	"date": "2017-06-13T13:55:02.603Z",
	"tags": {
		"categories": [
			"visual"
		],
		"languages": [
			"jupyter notebook",
			"shell"
		]
	},
	"content": "readme.md intro gentle introduction video technology, although 's aimed software developers / engineers, want make easy anyone learn. idea was born during mini workshop newcomers video technology. goal is introduce digital video concepts a simple vocabulary, lots visual elements practical examples possible, make knowledge available everywhere. please, feel free send corrections, suggestions improve .there be hands- sections require to docker installed this repository cloned.git clone https://github.com/leandromoreira/digital_video_introduction.gitcd digital_video_introduction./setup.shwarning: you a ./s/ffmpeg ./s/mediainfo command, means 're running containerized version that program, already includes the needed requirements. the hands- should performed the folder cloned repository. the jupyter examples must start server ./s/start_jupyter.sh copy url use in browser.indexintroindexbasic terminology ways encode color imagehands-: play around image colordvd is dar 4:3hands-: check video propertiesredundancy removalcolors, luminance our eyescolor modelconverting between ycbcr rgbchroma subsamplinghands-: check ycbcr histogramframe types frame (intra, keyframe)p frame (predicted)hands-: a video a single -frameb frame (bi-predictive)hands-: compare videos b-framesummarytemporal redundancy (inter prediction)hands-: see motion vectorsspatial redundancy (intra prediction)hands-: check intra predictions does video codec ?what? why? ?history birth av1 generic codec1st step - picture partitioninghands-: check partitions2nd step - predictions3rd step - transformhands-: throwing away different coefficients4th step - quantizationhands-: quantization5th step - entropy codingvlc codingarithmetic codinghands-: cabac vs cavlc6th step - bitstream formath.264 bitstreamhands-: inspect h.264 bitstreamreview does h.265 achieve better compression ratio h.264?online streaminggeneral architectureprogressive download adaptive streamingcontent protection to jupyterconferencesreferencesbasic terminology image be thought as 2d matrix. we about colors, can extrapolate idea seeing image a 3d matrix where additional dimensions are used provide color data. we chose represent colors using primary colors (red, green blue), define three planes: first for red, second green, the last for blue color.'ll call each point this matrix pixel (picture element). pixel represents intensity (usually numeric value) a given color. example, red pixel means 0 green, 0 blue maximum red. pink color pixel be formed a combination the three colors. using representative numeric range 0 255, pink pixel is defined red=255, green=192 blue=203. ways encode color imagemany possible models may used represent colors make an image. could, instance, an indexed palette where 'd need single byte represent each pixel instead the 3 needed using rgb model. such model could a 2d matrix instead a 3d matrix represent color, would save memory yield fewer color options. instance, at picture down below. first face is fully colored. others are red, green, blue planes (shown gray tones). can that red color be one contributes more ( brightest parts the second face) the final color while blue color contribution be mostly seen mario's eyes (last face) part his clothes, how planes contribute less (darkest parts) the mario's mustache. each color intensity requires certain amount bits, quantity is known bit depth. let's we spend 8 bits (accepting values 0 255) per color (plane), therefore have color depth 24 (8 * 3) bits we also infer we use 2 the power 24 different colors.'s great learn an image is captured the world the bits.another property an image is resolution, is number pixels one dimension. is often presented width × height, example, 4×4 image bellow.hands-: play around image color can play around image colors using jupyter (python, numpy, matplotlib etc). can learn image filters (edge detection, sharpen, blur...) .another property can while working images video is aspect ratio simply describes proportional relationship between width height an image pixel. people says movie picture is 16x9 usually are referring the display aspect ratio (dar), however also have different shapes individual pixels, call pixel aspect ratio (par).dvd is dar 4:3although real resolution a dvd is 704x480 still keeps 4:3 aspect ratio it has par 10:11 (704x10/480x11)finally, can define video a succession n frames time can seen another dimension, n is frame rate frames per second (fps). number bits per second needed show video is bit rate. example, video 30 frames per second, 24 bits per pixel, resolution 480x240 need 82,944,000 bits per second 82.944 mbps (30x480x240x24) we don't employ kind compression. the bit rate is nearly constant 's called constant bit rate (cbr) it can vary called variable bit rate (vbr). graph shows constrained vbr doesn't spend too many bits while frame is black. the early days, engineers came with technique doubling perceived frame rate a video display without consuming extra bandwidth. technique is known interlaced video; basically sends half the screen 1 \"frame\" the half the next \"frame\".today screens render mostly using progressive scan technique. progressive is way displaying, storing, transmitting moving images which the lines each frame are drawn sequence. we an idea how image is represented digitally, its colors are arranged, many bits per second we spend show video, it's constant (cbr) variable (vbr), a given resolution using given frame rate many terms such interlaced, par others.hands-: check video properties can check of explained properties ffmpeg mediainfo.redundancy removal learned is feasible use video without compression; single hour video 720p resolution 30fps require 278gb*. since using solely lossless data compression algorithms deflate (used pkzip, gzip, png), won't decrease required bandwidth sufficiently need find ways compress video.* found number multiplying 1280 x 720 x 24 x 30 x 3600 (width, height, bits per pixel, fps time seconds) order do , we exploit our vision works. 're better distinguishing brightness colors, repetitions time, video contains lot images few changes, the repetitions within image, each frame contains many areas using same similar color.colors, luminance our eyes eyes are more sensitive brightness colors, can test for yourself, at picture. you are unable see the colors the squares and b are identical the left side, 's fine, 's brain playing tricks us pay more attention light dark color. is connector, the same color, the right side we ( brain) easily spot in fact, 're same color.simplistic explanation how eyes the eye is complex organ, is composed many parts we are mostly interested the cones rods cells. eye contains 120 million rod cells 6 million cone cells. will abuse an oversimplification, let's try put colors brightness the eye's parts function. rod cells are mostly responsible brightness while cone cells are responsible color, are three types cones, each different pigment, namely: s-cones (blue), m-cones (green) l-cones (red).since have much more rod cells (brightness) cone cells (color), can infer we are more capable distinguishing dark light colors.once know we're more sensitive luma ( brightness an image) can try exploit .color model first learned to color images using rgb model there are models. fact, is model separates luma (brightness) chrominance (colors) it is known ycbcr*.* are more models do same separation. color model uses y represent brightness two color channels cb (chroma blue) cr (chrome red). ycbcr be derived rgb it can converted to rgb. using model can create full colored images we see down below.converting between ycbcr rgb may argue, can produce the colors without using green? answer question, 'll walk through conversion rgb ycbcr. 'll the coefficients the standard bt.601 was recommended the group itu-r* . first step is calculate luma, 'll the constants suggested itu replace rgb values.y = 0.299r + 0.587g + 0.114bonce had luma, can split colors (chroma blue red):cb = 0.564(b - y)cr = 0.713(r - y) we also convert back even the green using ycbcr.r = y + 1.402crb = y + 1.772cbg = y - 0.344cb - 0.714cr* groups standards are common digital video, usually define are standards, instance, is 4k? frame rate should use? resolution? color model?generally, displays (monitors, tvs, screens etc) utilize the rgb model, organized different manners, some them magnified below:chroma subsampling the image represented luma chroma components, can advantage the human visual system's greater sensitity luma resolution rather chroma selectively remove information. chroma subsampling is technique encoding images using less resolution chroma for luma. much should reduce chroma resolution?! turns that are already schemas describe to handle resolution the merge (final color = y + cb + cr). schemas are known subsampling systems are expressed a 3 part ratio - :x:y defines chroma resolution relation a x 2 block luma pixels. is horizontal sampling reference (usually 4),x is number chroma samples the row a pixels (horizontal resolution relation a), y is is numer changes chroma samples between first seconds rows a pixels. exception this exists 4:1:0, provides single chroma sample within each 4 x 4 block luma resolution.common schemes used modern codecs are: 4:4:4 ( subsampling)**, 4:2:2, 4:1:1, 4:2:0, 4:1:0 3:1:1.ycbcr 4:2:0 mergehere's merged piece an image using ycbcr 4:2:0, notice we spend 12 bits per pixel. can the same image encoded the main chroma subsampling types, images the row are final ycbcr while last row images shows chroma resolution. 's indeed great win such small loss.previously had calculated we needed 278gb storage keep video file one hour 720p resolution 30fps. we ycbcr 4:2:0 can cut size half (139 gb)* it is still far the ideal.* found value multiplying width, height, bits per pixel fps. previously needed 24 bits, we need 12.hands-: check ycbcr histogram can check ycbcr histogram ffmpeg. scene has more blue contribution is showed the histogram.frame types we move and try eliminate redundancy time before let's establish basic terminology. suppose have movie 30fps, here are first 4 frames. can lots repetitions within frames the blue background, doesn't change frame 0 frame 3. tackle problem, can abstractly categorize as three types frames. frame (intra, keyframe) i-frame (reference, keyframe, intra) is self-contained frame. doesn't rely anything be rendered, i-frame looks similar a static photo. first frame is usually i-frame we'll i-frames inserted regularly among types frames.p frame (predicted) p-frame takes advantage the fact almost always current picture be rendered using previous frame. instance, the second frame, only change was ball moved forward. can rebuild frame 1, using difference referencing the previous frame. <- hands-: a video a single -framesince p-frame uses less data why 't encode entire video a single -frame all rest being p-frames? you encoded video, start watch and a seek an advanced part the video, 'll notice takes time really move that part. 's a p-frame needs reference frame (-frame instance) be rendered.another quick test can is encode video using single -frame then encode inserting i-frame each 2s check size each rendition.b frame (bi-predictive) about referencing past future frames provide a better compression?! 's basically a b-frame is. <- -> hands-: compare videos b-frame can generate renditions, with b-frames other no b-frames all check size the file well the quality.summary frames types are used provide better compression, 'll how happens the next section, now, can of -frame is expensive while p-frame is cheaper the cheapest is b-frame.temporal redundancy (inter prediction)let's explore options have reduce repetitions time, type redundancy be solved techniques inter prediction. will try spend fewer bits encode sequence frames 0 1. thing can it's subtraction, simply subtract frame 1 frame 0 we just we need encode residual. if tell that is better method uses fewer bits?! , let's treat frame 0 a collection well-defined partitions then 'll try match blocks frame 0 frame 1. can of as motion estimation.wikipedia - block motion compensation\"block motion compensation divides the current frame non-overlapping blocks, the motion compensation vector tells where those blocks from ( common misconception is the previous frame is divided into non-overlapping blocks, the motion compensation vectors tell where those blocks move ). the source blocks typically overlap the source frame. video compression algorithms assemble current frame of pieces several different previously-transmitted frames.\" could estimate the ball moved x=0, y=25 x=6, y=26, x y values are motion vectors. further step can to save bits is encode the motion vector difference between last block position the predicted, the final motion vector be x=6 (6-0), y=1 (26-25) a real-world situation, ball be sliced n partitions the process is same. objects the frame move a 3d , the ball become smaller it moves the background. 's normal we won't find perfect match the block tried find match. here's superposed view our estimation vs real picture. we see when apply motion estimation data encode is smaller using simply delta frame techniques. can play around these concepts using jupyter.hands-: see motion vectors can generate video the inter prediction (motion vectors) ffmpeg. we use intel video pro analyzer ( is paid there is free trial version limits to the 10 frames).spatial redundancy (intra prediction) we analyze each frame a video 'll that are many areas are correlated.let's walk through example. scene is mostly composed blue white colors. is i-frame we 't previous frames predict but still compress . we encode red block selection. we at neighbors, can estimate there is trend colors around .we predict the frame continue spread colors vertically, means the colors the unknown pixels hold values its neighbors. prediction be wrong, that reason need apply technique (intra prediction) then subtract real values gives the residual block, resulting a much more compressible matrix compared the original.hands-: check intra predictions can generate video macro blocks their predictions ffmpeg. please check ffmpeg documentation understand meaning each block color. we use intel video pro analyzer ( is paid there is free trial version limits to the 10 frames). does video codec ?what? why? ?what? 's software / hardware compresses decompresses digital video. why? market society demands higher quality videos limited bandwidth storage. remember we calculated needed bandwidth 30 frames per second, 24 bits per pixel, resolution a 480x240 video? was 82.944 mbps no compression applied. 's only to deliver hd/fullhd/4k tvs the internet. ? we'll a brief at major techniques here.codec vs container common mistake beginners often is confuse digital video codec digital video container. can of containers a wrapper format contains metadata the video ( possible audio too), the compressed video be seen its payload.usually, extension a video file defines video container. instance, file video.mp4 is probably mpeg-4 part 14 container a file named video.mkv 's probably matroska. be completely sure the codec container format can ffmpeg mediainfo.historybefore jump the inner works a generic codec, let's back understand little better some old video codecs. video codec h.261 was born 1990 (technically 1988), it was designed work data rates 64 kbit/s. already uses ideas such chroma subsampling, macro block, etc. the of 1995, h.263 video codec standard was published continued be extended until 2001. 2003 first version h.264/avc was completed. the same , a company called truemotion released video codec a royalty-free lossy video compression called vp3. 2008, google bought company, releasing vp8 the same . in december 2012, google released vp9 it's supported roughly ¾ the browser market (mobile included).av1 is new video codec, royalty-free, open source being designed the alliance open media (aomedia) is composed the companies: google, mozilla, microsoft, amazon, netflix, amd, arm, nvidia, intel, cisco among others. first version 0.1.0 the reference codec was published april 7, 2016. birth av1early 2015, google was working vp10, xiph (mozilla) was working daala cisco open-sourced royalty-free video codec called thor. mpeg la announced annual caps hevc (h.265) fees 8 times higher h.264 soon changed rules again: annual cap,content fee (0.5% revenue) per-unit fees 10 times higher h264. alliance open media was created companies hardware manufacturer (intel, amd, arm , nvidia, cisco), content delivery (google, netflix, amazon), browser maintainers (google, mozilla), others. companies had common goal, royalty-free video codec then av1 was born a much simpler patent license. timothy b. terriberry did awesome presentation, is source this section, the av1 conception, license model its current state.'ll surprised know you analyze av1 codec through browser, to http://aomanalyzer.org/ps: you to learn more the history the codecs must learn basics behind video compression patents. generic codec're going introduce main mechanics behind generic video codec most these concepts are useful used modern codecs such vp9, av1 hevc. sure understand we're going simplify things lot. sometimes 'll a real example (mostly h.264) demonstrate technique.1st step - picture partitioning first step is divide frame several partitions, sub-partitions beyond. why? are many reasons, instance, we split picture can the predictions more precisely, using small partitions the small moving parts while using bigger partitions a static background.usually, codecs organize partitions slices ( tiles), macro ( coding tree units) many sub-partitions. max size these partitions varies, hevc sets 64x64 while avc uses 16x16 the sub-partitions reach sizes 4x4.remember we learned frames are typed?! , you apply those ideas blocks too, therefore can i-slice, b-slice, -macroblock etc.hands-: check partitions can use intel video pro analyzer ( is paid there is free trial version limits to the 10 frames). here are vp9 partitions analyzed.2nd step - predictionsonce have partitions, can predictions them. the inter prediction need send motion vectors the residual the intra prediction 'll send prediction direction the residual well.3rd step - transform we the residual block (predicted partition - real partition), can transform in way we know pixels can discard still keeping overall quality. are transformations this exact behavior.although are transformations, 'll more closely discrete cosine transform (dct). dct main features are:converts blocks pixels same-sized blocks frequency coefficients.compacts energy, making easy eliminate spatial redundancy.is reversible, .k.. you reverse pixels. 2 feb 2017, cintra, r. j. bayer, f. m published paper dct- transform image compressionrequires 14 additions .don't worry you didn't understand benefits every bullet point, 'll try make experiments order see real value it.let's the following block pixels (8x8): renders the following block image (8x8): we apply dct this block pixels we the block coefficients (8x8): if render block coefficients, 'll this image: you see looks nothing the original image, might notice the coefficient is very different all others. first coefficient is known the dc coefficient represents all samples the input array, something similar an average. block coefficients has interesting property is it separates high-frequency components the low frequency. an image, of energy be concentrated the lower frequencies, if transform image its frequency components throw away higher frequency coefficients, can reduce amount data needed describe image without sacrificing too much image quality.frequency means fast signal is changinglet's try apply knowledge acquired the test, 'll convert original image its frequency (block coefficients) using dct then throw away part the least important coefficients., we convert to frequency domain. then discard part (67%) the coefficients, mostly bottom right part it. then reconstruct image this discarded block coefficients (remember, needs be reversible) compare to original. we see resembles original image it introduced lots differences the original, throw away 67.1875% we still were able get least something similar the original. could more intelligently discard coefficients have better image quality that's next topic.each coefficient is formed using the pixels's important note each coefficient doesn't directly map a single pixel it's weighted sum all pixels. amazing graph shows the and second coefficient is calculated, using weights are unique each index.source: https://www.iem.thm.de/telekom-labor/zinke/mk/mpeg2beg/whatisit.htm can try visualize dct looking a simple image formation the dct basis. instance, here's a character being formed using each coefficient weight.hands-: throwing away different coefficients can play around the dct transform.4th step - quantization we throw away of coefficients, the last step (transform), kinda did form quantization. step is where chose lose information ( lossy part) in simple terms, 'll quantize coefficients achieve compression. can quantize block coefficients? simple method be uniform quantization, take block divide by single value (10) round value. can reverse (re-quantize) block coefficients? can that multiplying same value (10) divide first. approach isn't best it doesn't into account importance each coefficient, could a matrix quantizers instead a single value, matrix exploit property the dct, quantizing the bottom right less upper left, jpeg uses similar approach, can check source code see matrix.hands-: quantization can play around the quantization.5th step - entropy coding we quantized data (image blocks/slices/frames) still compress in lossless . there are many ways (algorithms) compress data. 're going briefly experience of , for deeper understanding can read amazing book understanding compression: data compression modern developers.vlc coding:let's suppose have stream the symbols: , e, r t their probability ( 0 1) is represented this table.ertprobability0.30.30.20.2 can assign unique binary codes (preferable small) the probable bigger codes the least probable ones.ertprobability0.30.30.20.2binary code0101101110let's compress stream eat, assuming would spend 8 bits each symbol, would spend 24 bits without compression. in case replace each symbol its code can save space. first step is encode symbol e is 10 the second symbol is which is added ( in mathematical ) [10][0] finally third symbol t makes final compressed bitstream be [10][0][1110] 1001110 only requires 7 bits (3.4 times less space the original).notice each code must a unique prefixed code huffman help to find numbers. though has issues are video codecs still offers method it's algorithm many applications requires compression.both encoder decoder must the symbol table its code, therefore, need send table too.arithmetic coding:let's suppose have stream the symbols: , e, r, s t their probability is represented this table.erstprobability0.30.30.150.050.2 this table mind, can build ranges containing the possible symbols sorted the frequents. let's encode stream eat, pick first symbol e is located within subrange 0.3 0.6 ( not included) we this subrange split again using same proportions used before within new range.let's continue encode stream eat, we the second symbol which is within new subrange 0.3 0.39 then take last symbol t we the same process again we the last subrange 0.354 0.372. just need pick number within last subrange 0.354 0.372, let's choose 0.36 we choose number within subrange. only number 'll able recover original stream eat. you about , it's if were drawing line within ranges ranges encode stream. reverse process (.k.. decoding) is equally easy, our number 0.36 our original range can run same process now using number reveal stream encoded behind number. the range, notice our number fits the slice, therefore, 's first symbol, we split subrange again, doing same process before, we'll notice 0.36 fits symbol and we repeat process came the last symbol t (forming original encoded stream eat).both encoder decoder must the symbol probability table, therefore need send table.pretty neat, isn't ? people are damn smart come with such solution, video codecs this technique ( at least offer as option). idea is lossless compress quantized bitstream, sure article is missing tons details, reasons, trade-offs etc. you should learn more a developer. newer codecs are trying use different entropy coding algorithms ans.hands-: cabac vs cavlc can generate streams, with cabac other cavlc compare time took generate each them well the final size.6th step - bitstream format we did these steps need pack compressed frames context these steps. need explicitly inform the decoder the decisions taken the encoder, such bit depth, color space, resolution, predictions info (motion vectors, intra prediction direction), profile, level, frame rate, frame type, frame number much more.'re going study, superficially, h.264 bitstream. first step is generate minimal h.264 * bitstream, can that using own repository ffmpeg../s/ffmpeg - /files//minimal.png -pix_fmt yuv420p /files/v/minimal_yuv420.h264* ffmpeg adds, default, the encoding parameter a sei nal, soon 'll define is nal. command generate raw h264 bitstream a single frame, 64x64, color space yuv420 using following image the frame.h.264 bitstream avc (h.264) standard defines the information be sent macro frames ( the network sense), called nal (network abstraction layer). main goal the nal is provision a \"network-friendly\" video representation, standard must on tvs (stream based), internet (packet based) among others. is synchronization marker define boundaries the nal's units. each synchronization marker holds value 0x00 0x00 0x01 except the very one is 0x00 0x00 0x00 0x01. we run hexdump the generated h264 bitstream, can identify least three nals the beginning the file. we said before, decoder needs know only picture data also details the video, frame, colors, used parameters, others. first byte each nal defines category type.nal type iddescription0undefined1coded slice a non-idr picture2coded slice data partition 3coded slice data partition b4coded slice data partition c5idr coded slice an idr picture6sei supplemental enhancement information7sps sequence parameter set8pps picture parameter set9access unit delimiter10end sequence12end stream......usually, first nal a bitstream is sps, type nal is responsible informing general encoding variables profile, level, resolution others. we skip first synchronization marker can decode first byte know type nal is first .for instance first byte the synchronization marker is 01100111, where first bit (0) is the field forbidden_zero_bit, next 2 bits (11) tell the field nal_ref_idc indicates whether nal is reference field not the rest 5 bits (00111) inform the field nal_unit_type, this case, 's sps (7) nal unit. second byte (binary=01100100, hex=0x64, dec=100) an sps nal is field profile_idc shows profile the encoder has used, this case, used constrained high-profile, 's high profile without support b (bi-predictive) slices. we read h.264 bitstream spec an sps nal 'll find many values the parameter name, category a description, instance, let's at pic_width_in_mbs_minus_1 pic_height_in_map_units_minus_1 fields.parameter namecategorydescriptionpic_width_in_mbs_minus_10ue(v)pic_height_in_map_units_minus_10ue(v)ue(v): unsigned integer exp-golomb-coded we some math the value these fields will end with resolution. can represent 1920 x 1080 using pic_width_in_mbs_minus_1 the value 119 ( (119 + 1) * macroblock_size = 120 * 16 = 1920), again saving space, instead encode 1920 did with 119. we continue examine created video a binary view (ex: xxd -b -c 11 v/minimal_yuv420.h264), can skip the last nal is frame itself. can its 6 bytes values: 01100101 10001000 10000100 00000000 00100001 11111111. we already the byte tell about type nal is, this case, (00101) 's idr slice (5) we further inspect :using spec info can decode type slice (slice_type), frame number (frame_num) among others important fields. order get values some fields (ue(v), (v), se(v) te(v)) need decode using special decoder called exponential-golomb, method is very efficient encode variable values, mostly there are many default values. values slice_type frame_num this video are 7 ( slice) 0 ( first frame). can the bitstream a protocol if want need learn more this bitstream please refer the itu h.264 spec. here's macro diagram shows where picture data (compressed yuv) resides. can explore others bitstreams the vp9 bitstream, h.265 (hevc) even new best friend av1 bitstream, they look similar? , but once learned you easily the others.hands-: inspect h.264 bitstream can generate single frame video use mediainfo inspect h.264 bitstream. fact, can see source code parses h264 (avc) bitstream. can use intel video pro analyzer is paid there is free trial version limits to the 10 frames that's okay learning purposes.review'll notice many the modern codecs uses same model learned. fact, let's at thor video codec block diagram, contains the steps studied. idea is you should able at least understand better innovations papers the area.previously had calculated we needed 139gb storage keep video file one hour 720p resolution 30fps we the techniques learned here, inter intra prediction, transform, quantization, entropy coding other can achieve, assuming are spending 0.031 bit per pixel, same perceivable quality video requiring 367.82mb vs 139gb store. choose use 0.031 bit per pixel based the example video provided here. does h.265 achieve better compression ratio h.264? that know more how codecs , then is easy understand new codecs are able deliver higher resolutions fewer bits. will compare avc hevc, let's keep mind it is almost always trade-off between more cpu cycles (complexity) compression rate.hevc has bigger more partitions ( sub-partitions) options avc, more intra predictions directions, improved entropy coding more, these improvements made h.265 capable compress 50% more h.264.online streaminggeneral architecture[todo]progressive download adaptive streaming[todo]content protection[todo] to jupyter sure have docker installed just run ./s/start_jupyter.sh follow instructions the terminal.conferencesdemuxed - can check last 2 events presentations..references richest content is here, 's where the info saw this text was extracted, based inspired . you deepen knowledge these amazing links, books, videos etc.online courses tutorials:https://www.coursera.org/learn/digital/https://.xiph.org/~tterribe/pubs/lca2012/auckland/intro_to_video1.pdfhttps://xiph.org/video/vid1.shtmlhttps://xiph.org/video/vid2.shtmlhttp://www.cambridgeincolour.com/tutorials/camera-sensors.htmhttp://www.slideshare.net/vcodex/-short-history--video-codinghttp://www.slideshare.net/vcodex/introduction--video-compression-13394338https://developer.android.com/guide/topics/media/media-formats.htmlhttp://www.slideshare.net/madhawakasun/audio-compression-23398426http://inst.eecs.berkeley.edu/~ee290t/sp04/lectures/02-motion_compensation_girod.pdfbooks:https://www.amazon.com/understanding-compression-data-modern-developers/dp/1491961538/ref=sr_1_1?s=books&ie=utf8&qid=1486395327&sr=1-1https://www.amazon.com/h-264-advanced-video-compression-standard/dp/0470516925https://www.amazon.com/practical-guide-video-audio-compression/dp/0240806301/ref=sr_1_3?s=books&ie=utf8&qid=1486396914&sr=1-3&keywords=+practical+guide++video+audiohttps://www.amazon.com/video-encoding-numbers-eliminate-guesswork/dp/0998453005/ref=sr_1_1?s=books&ie=utf8&qid=1486396940&sr=1-1&keywords=jan+ozerbitstream specifications:http://www.itu.int/rec/t-rec-h.264-201610-http://www.itu.int/itu-t/recommendations/rec.aspx?rec=12904&lang=enhttps://storage.googleapis.com/downloads.webmproject.org/docs/vp9/vp9-bitstream-specification-v0.6-20160331-draft.pdfhttp://iphome.hhi.de/wiegand/assets/pdfs/2012_12_ieee-hevc-overview.pdfhttp://phenix.int-evry.fr/jct/doc_end_user/current_document.php?id=7243http://gentlelogic.blogspot.com.br/2011/11/exploring-h264-part-2-h264-bitstream.htmlsoftware:https://ffmpeg.org/https://ffmpeg.org/ffmpeg-.htmlhttps://ffmpeg.org/ffprobe.htmlhttps://trac.ffmpeg.org/wiki/https://software.intel.com/en-/intel-video-pro-analyzerhttps://medium.com/@mbebenita/av1-bitstream-analyzer-d25f1c27072b#.d5a89oxz8non-itu codecs:https://aomedia.googlesource.com/https://github.com/webmproject/libvpx/tree/master/vp9https://.xiph.org/~xiphmont/demo/daala/demo1.shtmlhttps://.xiph.org/~jm/daala/revisiting/https://www.youtube.com/watch?v=lzpaldsmjbkhttps://fosdem.org/2017/schedule/event/om_av1/encoding concepts:http://x265.org/hevc-h265/https://arxiv.org/pdf/1702.00817v1.pdfhttps://trac.ffmpeg.org/wiki/debug/macroblocksandmotionvectorshttp://web.ece.ucdavis.edu/cerl/reliablejpeg/cung/jpeg.htmlhttp://www.adobe.com/devnet/adobe-media-server/articles/h264_encoding.htmlhttps://prezi.com/8m7thtvl4ywr/mp3--aac-explained/video sequences testing:http://bbb3d.renderfarming.net/download.htmlhttps://www..bldrdoc.gov/vqeg/video-datasets--organizations.aspxmiscellaneous:http://stackoverflow.com//24890903http://stackoverflow.com//24890903http://stackoverflow.com/questions/38094302/-to-understand-header--h264http://techblog.netflix.com/2016/08/-large-scale-comparison--x264-x265.htmlhttp://vanseodesign.com/web-design/color-luminance/http://www.biologymad.com/nervoussystem/eyenotes.htmhttp://www.compression.ru/video/codec_comparison/h264_2012/mpeg4_avc_h264_video_codecs_comparison.pdfhttp://www.csc.villanova.edu/~rschumey/csc4800/dct.htmlhttp://www.explainthatstuff.com/digitalcameras.htmlhttp://www.hkvstar.comhttp://www.hometheatersound.com/http://www.lighterra.com/papers/videoencodingh264/http://www.red.com/learn/red-101/video-chroma-subsamplinghttp://www.slideshare.net/manoharkuse/hevc-intra-codinghttp://www.slideshare.net/mwalendo/h264vs-hevchttp://www.slideshare.net/rvarun7777/final-seminar-46117193http://www.springer.com/cda/content/document/cda_downloaddocument/9783642147029-c1.pdfhttp://www.streamingmedia.com/articles/editorial/featured-articles/-progress-report--alliance--open-media--the-av1-codec-110383.aspxhttp://www.streamingmediaglobal.com/articles/readarticle.aspx?articleid=116505&pagenum=1http://yumichan.net/video-processing/video-compression/introduction--h264-nal-unit/https://cardinalpeak.com/blog/-h-264-sequence-parameter-set/https://cardinalpeak.com/blog/worlds-smallest-h-264-encoder/https://codesequoia.wordpress.com/category/video/https://developer.apple.com/library/content/technotes/tn2224/_index.htmlhttps://en.wikibooks.org/wiki/megui/x264_settingshttps://en.wikipedia.org/wiki/adaptive_bitrate_streaminghttps://en.wikipedia.org/wiki/aomedia_video_1https://en.wikipedia.org/wiki/chroma_subsampling#/media/file:colorcomp.jpghttps://en.wikipedia.org/wiki/cone_cellhttps://en.wikipedia.org/wiki/file:h.264_block_diagram_with_quality_score.jpghttps://en.wikipedia.org/wiki/inter_framehttps://en.wikipedia.org/wiki/intra-frame_codinghttps://en.wikipedia.org/wiki/photoreceptor_cellhttps://en.wikipedia.org/wiki/pixel_aspect_ratiohttps://en.wikipedia.org/wiki/presentation_timestamphttps://en.wikipedia.org/wiki/rod_cellhttps://.wikipedia.org/wiki/file:pixel_geometry_01_pengo.jpghttps://leandromoreira.com.br/2016/10/09/-to-measure-video-quality-perception/https://sites.google.com/site/linuxencoding/x264-ffmpeg-mappinghttps://softwaredevelopmentperestroika.wordpress.com/2014/02/11/image-processing--python-numpy-scipy-image-convolution/https://tools.ietf.org/html/draft-fuldseth-netvc-thor-03https://www.encoding.com/android/https://www.encoding.com/http-live-streaming-hls/https://www.iem.thm.de/telekom-labor/zinke/mk/mpeg2beg/whatisit.htmhttps://www.lifewire.com/cmos-image-sensor-493271https://www.linkedin.com/pulse/brief-history-video-codecs-yoav-nativhttps://www.linkedin.com/pulse/video-streaming-methodology-reema-majumdarhttps://www.vcodex.com/h264avc-intra-precition/https://www.youtube.com/watch?v=9vgtjj2wwmahttps://www.youtube.com/watch?v=lfxn9piogtyhttps://www.youtube.com/watch?v=lto-ajuqw3w&list=plzh6n4zxuckpkaj1_88vs-8z6yn9zx_p6https://www.youtube.com/watch?v=lwxu4rkzblw"
}