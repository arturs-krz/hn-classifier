{
	"_id": "14526807",
	"site": "https://github.com/Langhalsdino/Kubernetes-GPU-Guide",
	"title": "Automate deep learning training with Kubernetes GPU-cluster",
	"author": "Langhalsdino",
	"date": "2017-06-13T14:09:47.005Z",
	"tags": {
		"categories": [
			"opensource",
			"kubernetes",
			"kubernetes-cluster",
			"kubernetes-setup",
			"deep-learning",
			"gpu-computing",
			"distributed-systems"
		],
		"languages": [
			"shell",
			"jupyter notebook"
		]
	},
	"content": "readme.md to automate deep learning training kubernetes gpu-cluster guide should help fellow researchers hobbyists easily automate accelerate deep leaning training their own kubernetes gpu cluster.therefore will explain to easily set a gpu cluster multiple ubuntu 16.04 bare metal servers provide useful scripts .yaml files do entire setup you. the : if need kubernetes gpu-cluster other reasons, guide might helpful you well.why did write guide? have worked in intern the startup understand.ai noticed hassle firstly designing machine learning algorithm locally then bringing to cloud training different parameters datasets. second part, bringing to cloud extensive training, takes always longer thought, is frustrating involves usually lot pitfalls. this reason decided work this problem make second part effortless, simple quick. result this is handy guide, describes everyone setup own kubernetes gpu cluster accelerate work. new process the deep learning researchers: automated deep learning training a kubernetes gpu cluster significantly improves process training models the cloud. illustration visualizes new workflow involves two simple steps:disclaimer aware the following sections might opinionated. kubernetes is evolving, fast paced environment, means guide probably outdated times, depending the authors spare and individual contributions. due this fact contributions are highly appreciated.table contentsquick kubernetes reviverough overview the structure the clusterinitiate nodes setupsetup instructions fast setup scriptmanually step step instructions to build gpu containeressential parts .ymlexample gpu deployment helpful commandsacknowledgementsauthorslicensequick kubernetes revive articles might helpful, you need refresh kubernetes knowledge:introduction kubernetes digitaloceankubernetes conceptskubernetes examplekubernetes basics - interactive tutorialrough overview the structure the cluster main idea is have small cpu master node controls cluster gpu-worker nodes.initiate nodesbefore can the cluster, is important initiate cluster . therefore each node has be initiated manually afterwards has join cluster. setup setup works perfectly the described case - other cases, operating systems etc. further adaptions be necessary.masterubuntu 16.04 root access used google compute engine vm-instancessh accessufw deactivatedenabled ports (udp tcp)6443, 443, 808030000-32767 ( if apps need )these be used access services outside the clusterworkerubuntu 16.04 root access used google compute engine vm-instancessh accessufw deactivatedenabled ports (udp tcp)6443, 443 security: course kind firewall should enabled you to this production - ufw is disabled reasons simplicity. setting kubernetes for actual production workload should course involve enabling kind firewall ufw, iptables e.g. firewall your cloud provider. note setting a cluster the cloud may more complicated. cloud provider usually offers firewall its own is separate the host level firewall. may to deactivate ufw also enable rules the cloud providers firewall make steps this document !setup instructions instruction cover experience ubuntu 16.04 may may be suited transfer other oss. have created scripts fully initiate master worker node described below. you to the fast track, use scripts. otherwise recommend read step step instructions.fast track - setup scriptok, let's the fast track. copy corresponding scripts your master workers.master nodeexecute initialization script remember token token look this: --token f38242.e7f3xxxxxxxxe231e.chmod +x init-master.shsudo ./init-master.sh <ip--master>worker nodeexecute initialization script the correct token ip your master. port is usually 6443.chmod +x init-worker.shsudo ./init-worker.sh <token--master> <ip--master>:<port>detailed step step instructionsmaster node1. add kubernetes repository the packagemanagersudo bash -c 'apt- update && apt- install -y apt-transport-httpscurl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -cat <<eof >/etc/apt/sources.list.d/kubernetes.listdeb http://apt.kubernetes.io/ kubernetes-xenial maineofapt- update'2. install docker-engine, kubeadm, kubectl, kubernetes-cnisudo apt- install -y docker-enginesudo apt- install -y kubelet kubeadm kubectl kubernetes-cnisudo groupadd dockersudo usermod -ag docker $userecho ' might need reboot / relogin make docker correctly'3. since want build cluster uses gpus need enable gpu acceleration the master node.keep mind, this instruction may become obsolete change completely a later version kubernetes!3.add gpu support the kubeadm configuration, while cluster is initialized. has be done every node across cluster, if of don't any gpus.sudo vim /etc/systemd/system/kubelet.service.d/<<number>>-kubeadm.conftherefore, append execstart the flag --feature-gates=\"accelerators=true\", it look this:execstart=/usr/bin/kubelet $kubelet_kubeconfig_args [...] --feature-gates=\"accelerators=true\"3.ii restart kubeletsudo systemctl daemon-reloadsudo systemctl restart kubelet4. we initialize master node.therefore will need ip your master node.furthermore step provide with credentials add further worker nodes, remember token token look this: --token f38242.e7f3xxxxxxxxe231e 130.211.xxx.xxx:6443sudo kubeadm init --apiserver-advertise-address=<ip-address>5. since kubernetes 1.6 changed abac roll-management rbac need advertise credentials the user. will need perform step each you log the machine!!sudo cp /etc/kubernetes/admin.conf $home/sudo chown $(id -u):$(id -g) $home/admin.confexport kubeconfig=$home/admin.conf6. install network add-ons that pods communicate each . kubernetes 1.6 has requirements the network add-, some them are:cni-based networksrbac support googlesheet contains selection suitable network add-. link : googlesheet network add- comparison will wave-works, because my personal preference ;)kubectl apply -f https://git.io/weave-kube-1.65.ii are ready go, check pods all pods are online confirm everything is working ;)kubectl pods ---namespacesn. you to tear down master, will need reset master nodesudo kubeadm resetworker node beginning should familiar you make process lot faster ;)1. add kubernetes repository the packagemanagersudo bash -c 'apt- update && apt- install -y apt-transport-httpscurl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -cat <<eof >/etc/apt/sources.list.d/kubernetes.listdeb http://apt.kubernetes.io/ kubernetes-xenial maineofapt- update'2. install docker-engine, kubeadm, kubectl, kubernetes-cnisudo apt- install -y docker-enginesudo apt- install -y kubelet kubeadm kubectl kubernetes-cnisudo groupadd dockersudo usermod -ag docker $userecho ' might need reboot / relogin make docker correctly'3. since want build cluster uses gpus need enable gpu acceleration the worker nodes have gpu installed.keep mind, this instruction may become obsolete change completely a later version kubernetes!3.add gpu support the kubeadm configuration, while cluster is initialized. has be done every node across cluster, if of don't any gpus.sudo vim /etc/systemd/system/kubelet.service.d/<<number>>-kubeadm.conftherefore, append execstart the flag --feature-gates=\"accelerators=true\", it look this:execstart=/usr/bin/kubelet $kubelet_kubeconfig_args [...] --feature-gates=\"accelerators=true\"3.ii restart kubeletsudo systemctl daemon-reloadsudo systemctl restart kubelet4. we add worker the cluster.therefore will need remember token your master node, take deep dive your notes xdsudo kubeadm join --token f38242.e7f3xxxxxxe231e 130.211.xxx.xxx:64435. finished, check nodes your master see everything worked.kubectl nodesn. you to tear down worker node, will need remove node the cluster reset worker node.furthermore will beneficial remove worker node the cluster master:kubectl delete node <worker node name> worker nodesudo kubeadm resetclient order control cluster e.g. master your client, will need authenticate client the right user. guid wont cover creating separate user client, will copy user the master node. will easier, trust [instruction add custom user, be added the future]1. install kubectl your client. have tested on may mac, linux should as .i dont about windows, who cares windows anyway :d macbrew install kubectl ubuntu either follow official guide: https://kubernetes.io/docs/tasks/tools/install-kubectl/ you extract needed steps the instruction the worker above ( probably work ubuntu).2. copy admin authentication the master your clientscp uai@130.211.xxx.64:~/admin.conf ~/.kube/3. add admin.conf configuration credentials kubernetes configuration. will need do for every agentexport kubeconfig=~/.kube/admin.conf are ready use kubectl you local client.3.ii can test listing your podskubectl pods ---namespacesinstall kubernetes dashboard kubernetes dashboard is pretty beautiful gives script kiddies me access a lot functionality. order use dashboard will need get client running, rbac ensure you perform steps directly the master from client1. check the dashboard is already installedkubectl pods ---namespaces | grep dashboard2. the dashboard isnt installed, install ;)kubectl create -f https://git.io/kube-dashboard this did work check the containers defined the .yaml git.io/kube-dashboard exist. ( bug cost a lot time) order have access your dashboard will need authenticate yourself your client.3. proxy dashboard your clientrun on client:kubectl proxy4. access dashboard within browser visiting127.0.0.1:8001/ui to build gpu container guide should help to a docker container running needs gpu access. this guide have chosen build example docker container, uses tensorflow gpu binaries can run tensorflow programs a jupyter notebook.keep mind, this guide has been written kubernetes 1.6, therefore further changes compromise guide.essential parts .yml order get nvidia gpu cuda running have pass nvidia driver cuda libraries your container. we use hostpath make available the kubernetes pod. actual path differ machine machine, since are set your nvidia driver cuda installation.volumes: - hostpath: path: /usr/lib/nvidia-375/bin name: bin - hostpath: path: /usr/lib/nvidia-375 name: libmount volumes the driver cuda the right directory your container. might differ, due specific requirements your container.volumemounts: - mountpath: /usr/local/nvidia/bin name: bin - mountpath: /usr/local/nvidia/lib name: libsince want tell kubernetes you need n gpus , can define requirements here.resources: limits: alpha.kubernetes.io/nvidia-gpu: 1thats , it is everything need build kuberntes 1.6 container note the end, describes overall experience:kubernetes + docker + machine learning + gpus = pure awesomenessexample gpu deployment example-gpu-deployment.yaml file describes parts, deployment a service, since want make jupyter notebook available the outside.run kubectl apply make available the outsidekubectl create -f deployment.yaml deployment.yaml file looks this:---apiversion: extensions/v1beta1kind: deploymentmetadata: name: tf-jupyterspec: replicas: 1 template: metadata: labels: app: tf-jupyter spec: volumes: - hostpath: path: /usr/lib/nvidia-375/bin name: bin - hostpath: path: /usr/lib/nvidia-375 name: lib containers: - name: tensorflow image: tensorflow/tensorflow:0.11.0rc0-gpu ports: - containerport: 8888 resources: limits: alpha.kubernetes.io/nvidia-gpu: 1 volumemounts: - mountpath: /usr/local/nvidia/bin name: bin - mountpath: /usr/local/nvidia/lib name: lib---apiversion: v1kind: servicemetadata: name: tf-jupyter-service labels: app: tf-jupyterspec: selector: app: tf-jupyter ports: - port: 8888 protocol: tcp nodeport: 30061 type: loadbalancer--- order verify the setup works, visit instance jupyternotebook http://<ip--master>:30061. we need verify, your instance jupyternotebook access gpu. therefore, run the following code a notebook. will list devices are available tensorflow. tensorflow.python.client import device_libdef get_available_devices(): local_device_protos = device_lib.list_local_devices() return [x.name x local_device_protos]print(get_available_devices()) should output something the following [u'/cpu:0', u'/gpu:0']. helpful commands commands basic outputkubectl services # list services the namespacekubectl pods ---namespaces # list pods all namespaceskubectl pods -o wide # list pods the namespace, more detailskubectl deployments # list deploymentskubectl deployment -dep # list particular deploymentdescribe commands verbose outputkubectl describe nodes <node-name>kubectl describe pods <pod-name>deleting resourceskubectl delete -f ./pod.yaml # delete pod using type name specified pod.yamlkubectl delete pod,service baz foo # delete pods services same names \"baz\" \"foo\"kubectl delete pods,services -l name=<label> # delete pods services label name=mylabelkubectl -n <namespace> delete po,svc -- # delete pods services namespace -ns into bash console one your pods:kubectl exec - <pod-name> -- /bin/bashacknowledgements are lot guides, github repositories, issues people there helped a lot. i to thank everybody their help.specially startup understand.ai their support.authorsfrederic tausch - initial - langhalsdinolicense project is licensed under mit license - the license.md file details"
}